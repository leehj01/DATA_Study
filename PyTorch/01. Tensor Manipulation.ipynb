{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy review\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t :  [0. 1. 2. 3. 4. 5. 6.]\n",
      "몇개의 차원으로 이루어졌나? :  1\n",
      "Shape  :  (7,)\n",
      "\n",
      "t[0], t[1], t[-1] =  0.0 1.0 6.0\n",
      "t[2:5] t[4:-1]    =  [2. 3. 4.] [4. 5.]\n",
      "t[:2] t[3:]       =  [0. 1.] [3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "# 1D Array with Numpy\n",
    "\n",
    "# numpy 를 선언하기 \n",
    "t = np.array([0., 1., 2., 3., 4., 5., 6.])\n",
    "print('t : ',t)\n",
    "\n",
    "print('몇개의 차원으로 이루어졌나? : ', t.ndim)\n",
    "print('Shape  : ', t.shape)\n",
    "print()\n",
    "print('t[0], t[1], t[-1] = ', t[0], t[1], t[-1])  # Element\n",
    "print('t[2:5] t[4:-1]    = ', t[2:5], t[4:-1])    # Slicing\n",
    "print('t[:2] t[3:]       = ', t[:2], t[3:])       # # Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t :  \n",
      " [[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "\n",
      "몇개의 차원으로 이루어졌나? :  2\n",
      "Shape  :  (4, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2D Array with Numpy\n",
    "\n",
    "t= np.array([[1,2,3], [4,5,6],[7,8,9], [10,11,12]])\n",
    "print('t : ','\\n', t)\n",
    "print()\n",
    "print('몇개의 차원으로 이루어졌나? : ', t.ndim)\n",
    "print('Shape  : ', t.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Array with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t :  tensor([0., 1., 2., 3., 4., 5., 6.])\n",
      "몇개의 차원으로 이루어졌나? :  1\n",
      "Shape  :  torch.Size([7])\n",
      "Shape  :  torch.Size([7])\n",
      "\n",
      "t[0], t[1], t[-1] =  tensor(0.) tensor(1.) tensor(6.)\n",
      "t[2:5] t[4:-1]    =  tensor([2., 3., 4.]) tensor([4., 5.])\n",
      "t[:2] t[3:]       =  tensor([0., 1.]) tensor([3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "# torch 를 선언하기 \n",
    "t = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])\n",
    "print('t : ',t)\n",
    "\n",
    "print('몇개의 차원으로 이루어졌나? : ', t.dim())  # rank\n",
    "print('Shape  : ', t.shape)\n",
    "print('Shape  : ', t.size())\n",
    "print()\n",
    "print('t[0], t[1], t[-1] = ', t[0], t[1], t[-1])  # Element\n",
    "print('t[2:5] t[4:-1]    = ', t[2:5], t[4:-1])    # Slicing\n",
    "print('t[:2] t[3:]       = ', t[:2], t[3:])       # # Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Array with Numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t :  \n",
      " tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "\n",
      "몇개의 차원으로 이루어졌나? :  2\n",
      "Shape  :  torch.Size([4, 3])\n",
      "Shape  :  torch.Size([4, 3])\n",
      "\n",
      "tensor([ 2.,  5.,  8., 11.])\n",
      "torch.Size([4])\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 4.,  5.],\n",
      "        [ 7.,  8.],\n",
      "        [10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "t= torch.FloatTensor([[1,2,3], [4,5,6],[7,8,9], [10,11,12]])\n",
    "print('t : ','\\n', t)\n",
    "print()\n",
    "print('몇개의 차원으로 이루어졌나? : ', t.dim())\n",
    "print('Shape  : ', t.shape)\n",
    "print('Shape  : ', t.size())\n",
    "print()\n",
    "print(t[:,1])  # 첫번째 차원은 다 가져오고, 두번째꺼에서는 1 번째만 가져오기\n",
    "print(t[:,1].size())  # 벡터 \n",
    "print(t[:, :-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "- pytorch에는 Broadcasting기능을 제공한다.\n",
    "- 자동적으로 사이즈를 맞춰서 연산을 수행한다.\n",
    "- Broadcasting 는 자동적으로 실행되기 때문에, 사용자 입장에서 조심스럽게 사용해야한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5.]])\n",
      "\n",
      "tensor([[4., 5.]])\n",
      "\n",
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# same shape\n",
    "m1 = torch.FloatTensor([[3,3]])\n",
    "m2 = torch.FloatTensor([[2,2]])\n",
    "\n",
    "print(m1 + m2)\n",
    "print()\n",
    "\n",
    "# vector + scalar\n",
    "# 원래는 크기가 안맞아서 연산이 안되지만, 자동으로 사이즈를 맞춰줌 \n",
    "m1 = torch.FloatTensor([[1,2]])\n",
    "m2 = torch.FloatTensor([[3]])  # 3 - > [[3,3]]\n",
    "\n",
    "print(m1 + m2)  # [[1,2]] + [[3,3]] = [[4, 5]]\n",
    "print()\n",
    "\n",
    "# 2 x 1 vector +  1 x 2 vector\n",
    "# 텐서간의 연산에도 자동으로 1이 들어있는 차원을 늘려주어서 적용됨\n",
    "m1 = torch.FloatTensor([[1,2]])\n",
    "m2 = torch.FloatTensor([[3],[4]])  \n",
    "\n",
    "print(m1 + m2)\n",
    "# [[1,2],[1,2]] + [[3,3],[4,4]] = [ [4,5],[5,6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplication vs Matrix Multiplication ( 곱셈  vs 행렬 곱셈 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일반적인 곱셈\n",
      "--------------\n",
      "Shape of Matrix 1 : torch.Size([2, 2])\n",
      "Shape of Matrix 1 : torch.Size([2, 1])\n",
      "mul :  \n",
      " tensor([[1., 2.],\n",
      "        [6., 8.]])\n",
      "\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n",
      "\n",
      "행렬 곱셈\n",
      "--------------\n",
      "Shape of Matrix 1 : torch.Size([2, 2])\n",
      "Shape of Matrix 1 : torch.Size([2, 1])\n",
      "mul :  \n",
      " tensor([[ 5.],\n",
      "        [11.]])\n"
     ]
    }
   ],
   "source": [
    "print('일반적인 곱셈')\n",
    "print('--------------')\n",
    "m1 = torch.FloatTensor([[1,2],[3,4]])\n",
    "m2 = torch.FloatTensor([[1],[2]])\n",
    "\n",
    "print('Shape of Matrix 1 :', m1.shape)  # 2 x 2\n",
    "print('Shape of Matrix 1 :', m2.shape)  # 2 x 1 -> 브로드 캐스팅 2 X 2 됨\n",
    "print('mul : ','\\n',m1 * m2)            # 2 x 2\n",
    "\n",
    "# [[1,2],[3,4]] X [[1,1], [2,2]]= [[1,2],[6,8]]\n",
    "print()\n",
    "print(m1.mul(m2))\n",
    "\n",
    "print()\n",
    "print('행렬 곱셈')\n",
    "print('--------------')\n",
    "m1 = torch.FloatTensor([[1,2],[3,4]])\n",
    "m2 = torch.FloatTensor([[1],[2]])\n",
    "\n",
    "print('Shape of Matrix 1 :', m1.shape)  # 2 x 2\n",
    "print('Shape of Matrix 1 :', m2.shape)  # 2 x 1\n",
    "# 행렬곱은 뒤의 차원과 앞의 차원의 크기가 같으면 됨 \n",
    "print('mul : ','\\n',m1.matmul(m2))      # 2 x 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean : tensor(1.5000)\n",
      "<built-in method mean of Tensor object at 0x00000216EC1A6048>\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(2.5000)\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "t= torch.FloatTensor([1,2])\n",
    "print('mean :', t.mean())\n",
    "\n",
    "# longTensor 에 대해서는 mean을 잘 수행하지 못한다.\n",
    "t = torch.LongTensor([1,2])\n",
    "try :\n",
    "    print(t.mean)\n",
    "except Exception as exc:\n",
    "    print(exc)\n",
    "    \n",
    "    \n",
    "t = torch.FloatTensor([[1,2],[3,4]])\n",
    "print(t)\n",
    "\n",
    "print(t.mean())\n",
    "print(t.mean(dim=0))   # dimension argument - dim 0을 없앤다고 생각하면 됨\n",
    "print(t.mean(dim=1))\n",
    "print(t.mean(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(10.)\n",
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1,2],[3,4]])\n",
    "print(t)\n",
    "\n",
    "print(t.sum())\n",
    "print(t.sum(dim=0))\n",
    "print(t.sum(dim=1))\n",
    "print(t.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Max and Argmax\n",
    "- max : tensor나 행렬에 대해서 가장 큰값을 찾아주는 것\n",
    "- argmax : 그 인덱스 값을 리턴해주는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(4.)\n",
      "\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "\n",
      "MAX :  tensor([3., 4.])\n",
      "\n",
      "Argmax :  tensor([1, 1])\n",
      "\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1,2],[3,4]])\n",
    "print(t)\n",
    "\n",
    "print(t.max())\n",
    "\n",
    "print()\n",
    "\n",
    "# dimension 의 정보도 줄 수 있음\n",
    "print(t.max(dim=0))  # max 의 값 뿐만 아니라, 인덱스값도 같이 받아줌 \n",
    "print()\n",
    "print('MAX : ', t.max(dim=0)[0])\n",
    "print()\n",
    "print('Argmax : ', t.max(dim=0)[1])\n",
    "print()\n",
    "print(t.max(dim=1))\n",
    "print()\n",
    "print(t.max(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
