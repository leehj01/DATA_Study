{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14장. 웹데이터 수집\n",
    "## * 웹데이터 수집 종류\n",
    "- 공공 데이터 수집\n",
    "    - open API ㅣ용 \n",
    "    - URL이 존재\n",
    "    - CSV/ JSON형식으로 이용\n",
    "- 뉴스 기사 크롤링\n",
    "    - RSS서비스\n",
    "    - XML형식\n",
    "- SNS 데이터 크롤링\n",
    "    - 트위터, 댓글 등\n",
    "    - Text 형식 또는 json 형식\n",
    "- 웹 데이터 수집 \n",
    "\n",
    "\n",
    "## 1절 . 뷰티풀솝과 파서\n",
    "- 뷰티풀솝 : 내가 원하는 내용을 뽑아서 사용하는것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(\"http://coderby.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install requests_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_file import FileAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.mount(\"file://\",FileAdapter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = s.get(\"file:///sample.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(res.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el = soup.select_one(\"head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_el = el.select_one(\"title\")\n",
    "soup.select_one(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_el.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select(\"div.contents\")[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 네이버 영화 랭킹 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://movie.naver.com/movie/sdb/rank/rmovie.nhn'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "for i in range(50):\n",
    "    result = soup.select(\".tit3\")[i].text.strip()\n",
    "    result1 = soup.select(\".tit3 > a\")[i].attrs['href']\n",
    "    print(i+1,\"위 :\",result, result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://movie.naver.com/movie/sdb/rank/rmovie.nhn'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "\n",
    "t = soup.select('.title')\n",
    "movie_list=[]\n",
    "for movie in t:\n",
    "    try :\n",
    "        print(movie.select_one(\"td.title > div>a\").text)\n",
    "        movie_list.append(movie.select_one(\"td.title > div>a\").text)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.c_[np.arange(1,51),movie_list],columns=[\"순위\",\"영화제목\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://finance.naver.com/marketindex/?tabSel=exchange#tab_section'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "soup.select(\"div.head_info span.value\")[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3절. Selenium을 이용한 웹 데이터 수집\n",
    "### 3.1. 셀리니움\n",
    "#### 1)  셀레니움 파이썬 바이닝 \n",
    "- 셀리니움을 파이썬 용도로 만들어 놓은것\n",
    "- 웹드라이버가 필요함.\n",
    "- 브라우저를 제어하는 것. \n",
    "- 크롬 설정에 들어가서 맞는 버전 대로, https://chromedriver.chromium.org/downloads 에서 크롬 드라이버 다운받기\n",
    "- pip install selenium 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:/chromedriver\") # 크롬 드라이버의 위치르 지정\n",
    "# 새로운 창이 뜸. # 창을 끄면 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://www.python.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_el =driver.find_element_by_id(\"id-search-field\")\n",
    "input_el # 이걸 가지고 제어하려는 목적 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_el.clear()  # 뭘입력되어있는지 모르니깐 다 지우자 라는 의미\n",
    "input_el.send_keys(\"pycon\") # element마다 실행용어가 다름. 이건 단순히 pycon을 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Keys. # tab을 눌러서 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_el.send_keys(Keys.RETURN) # 엔터를 치는 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_list = driver.find_elements_by_css_selector(\"form h3>a\") # 제목 불러오기\n",
    "result_list \n",
    "# 여러개를 찾을 때는 element에 s 를 붙여주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in result_list:\n",
    "    print(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close() # 브라우저 닫기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. 페이지 탐색\n",
    "#### 1) 페이지와 상포작용하기. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:/chromedriver\") # 크롬 드라이버의 위치르 지정\n",
    "# 새로운 창이 뜸. # 창을 끄면 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http:www.google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = driver.find_element_by_id(\"passwd-id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "element = driver.find_element_by_xpath(\"//select[@name = 'name']\")\n",
    "all_options = element.find_elements_by_tag_name(\"option\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4절.연습문제\n",
    "### 4.1. 실습형 \n",
    "#### 1) 문제 :  예스 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'http://www.yes24.com/24/category/bestseller'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text,\"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이서윤,홍주연 저 '"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"#bestList ol .aupu\")[0].text.split(\"|\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'http://www.yes24.com/24/category/bestseller'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "name_list = []\n",
    "writer_list = []\n",
    "price_list = []\n",
    "for i in range(10):\n",
    "    name = soup.select(\"p:nth-of-type(3) a\")[i].text\n",
    "    name_list.append(name)\n",
    "    writer = soup.select(\"#bestList ol .aupu\")[i].text.split(\"|\")[0]\n",
    "    writer_list.append(writer)\n",
    "    price = soup.select(\"#bestList .price strong\")[i].text\n",
    "    price_list.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = {\"name\":name_list,\"writer\":writer_list,\"price\":price_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>writer</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>더 해빙 The Having</td>\n",
       "      <td>이서윤,홍주연 저</td>\n",
       "      <td>14,400원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>지리의 힘</td>\n",
       "      <td>팀 마샬 저/김미선 역</td>\n",
       "      <td>15,300원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>흔한남매 4</td>\n",
       "      <td>흔한남매 원저/백난도 글/유난희 그림/샌드박스 네트워크 감수</td>\n",
       "      <td>10,800원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020 제11회 젊은작가상 수상작품집</td>\n",
       "      <td>강화길,최은영,김봉곤,김초엽,장류진 저 외 2명</td>\n",
       "      <td>4,950원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>내가 원하는 것을 나도 모를 때</td>\n",
       "      <td>전승환 저</td>\n",
       "      <td>14,400원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>설민석의 한국사 대모험 13</td>\n",
       "      <td>설민석,스토리박스 글/정현희 그림/태건 역사 연구소 감수</td>\n",
       "      <td>10,800원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>설민석의 세계사 대모험 5</td>\n",
       "      <td>설민석,잼스토리 글/박성일 그림</td>\n",
       "      <td>10,800원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>좋은 말씀</td>\n",
       "      <td>법정 저</td>\n",
       "      <td>15,300원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>오래 준비해온 대답</td>\n",
       "      <td>김영하 저</td>\n",
       "      <td>14,850원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>진짜 부자 가짜 부자</td>\n",
       "      <td>사경인 저</td>\n",
       "      <td>15,300원</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                              writer    price\n",
       "0        더 해빙 The Having                          이서윤,홍주연 저   14,400원\n",
       "1                  지리의 힘                       팀 마샬 저/김미선 역   15,300원\n",
       "2                 흔한남매 4  흔한남매 원저/백난도 글/유난희 그림/샌드박스 네트워크 감수   10,800원\n",
       "3  2020 제11회 젊은작가상 수상작품집         강화길,최은영,김봉곤,김초엽,장류진 저 외 2명    4,950원\n",
       "4      내가 원하는 것을 나도 모를 때                              전승환 저   14,400원\n",
       "5        설민석의 한국사 대모험 13    설민석,스토리박스 글/정현희 그림/태건 역사 연구소 감수   10,800원\n",
       "6         설민석의 세계사 대모험 5                  설민석,잼스토리 글/박성일 그림   10,800원\n",
       "7                  좋은 말씀                               법정 저   15,300원\n",
       "8             오래 준비해온 대답                              김영하 저   14,850원\n",
       "9            진짜 부자 가짜 부자                              사경인 저   15,300원"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://fs.jtbc.joins.com/RSS/economy.xml'\n",
    "response = requests.get(url)\n",
    "jtbc = BeautifulSoup(response.content,\"xml\") # extensible markup language\n",
    "jtbc_list = jtbc.select(\"item > link\")\n",
    "len(jtbc_list)\n",
    "\n",
    "news_data = []\n",
    "for link in jtbc_list:\n",
    "    news = requests.get(link.text)\n",
    "    news_soup = BeautifulSoup(news.content, \"html.parser\")\n",
    "    news_content = news_soup.select_one(\"#articlebody > .article_content\")\n",
    "    news_data.append(news_content.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[앵커]정부가 서울 도심에 주택 7만 가구를 짓기로 했습니다. 지지부진한 재개발을 돕고 비어있는 자투리 땅을 개발해서 내후년까지 부지를 확보한다는 계획입니다. 용산역 정비창에는 '미니 신도시 급'인 8000가구가 들어섭니다.강남의 집값이 다시 들썩이지 않도록 쐐기를 박겠다는 의도로 보입니다.백민경 기자입니다.[기자]서울 용산역 정비창입니다.'단군 이래 최대 개발사업'이라는 용산국제업무지구 사업이 실패한 뒤 비어 있는 땅입니다.정부는 이곳에 8000가구의 미니신도시급 아파트 단지를짓기로 했습니다.중구청이 있는 청사 부지, 흑석동 유휴지, 해군복지단 등 자투리땅도 활용합니다.조합갈등이심하거나사업성이부족해멈춰있는재개발사업에는정부가참여해 사업을 돕습니다.재개발을투명하게운영하는 동시에 속도를내겠다는취지입니다.또 비어있는사무실이나상가를 사서 1인주거용장기공공임대주택으로활용할 계획입니다.정부는이렇게 해서 2022년까지서울도심에7만 가구를 지을부지를 확보하기로 했습니다.전문가들은 정부의 이 같은 공급방안을 내놓은 건 강남 집값에 쐐기를 박기 위한측면이 크다고 봅니다.강남 집값은 강도 높은 규제에코로나19 확산 이후 경기침체 우려로5주 연속 떨어졌습니다.이런 상황에서 공급을 늘리면 집값이 안정세를 이어갈 가능성이 크다는 게 정부의 판단이라는 겁니다.\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data[0].replace(\"\\n\",\"\").replace(\"\\xa0\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n[앵커]정부가 서울 도심에 주택 7만 가구를 짓기로 했습니다. 지지부진한 재개발...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n1. KDI \"2분기 이후 청년고용 충격\"코로나 여파로 인한 청년층 고용 충격이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n[앵커]이재용 부회장은 10분 동안 미리 준비해온 사과문을 읽었습니다. 두 차례...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n[앵커]이재용 삼성전자 부회장이 어제(6일) 대국민 사과문을 발표했습니다. 경영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n[앵커]그동안 사회적 거리두기로 집에서 온라인 쇼핑하는 분들이 많았는데요. 어떤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n[앵커]한때 2~3시간 줄을 서야 살 수 있던 마스크를 요즘엔 기다리지 않아도 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n[앵커]정부가 서울 도심에 주택 7만 가구를 짓기로 했습니다. 지지부진한 재개발...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n■ 인용보도 시 프로그램명 'JTBC &lt;뉴스룸&gt;'을 밝혀주시기 바랍니다. 저작권...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n[앵커]이재용 부회장은 10분간 준비해 온 사과문을 읽으며 두 번 고개를 숙였습...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n[앵커]삼성전자 이재용 부회장이 오늘(6일) 대국민 사과문을 발표했습니다. 경영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\n[앵커]이재용 삼성전자 부회장이 경영권 승계와 노조 문제 등과 관련해 대국민 사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\n■ 인용보도 시 프로그램명 'JTBC &lt; 아침&amp; &gt;'을 밝혀주시기 바랍니다. 저...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\n[앵커]어제(5일) 마트와 백화점은 쇼핑객들로 종일 붐볐는데요. 소비 심리가 본...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\n[앵커]집값을 잡기 위해 종합부동산세를 올리려던 정부의 계획이 20대 국회에 가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\n1. \"지역화폐 바가지 땐 가맹점 박탈\"이재명 경기도지사가 이번에는 재난기본소득...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\\n[앵커]코로나19는 금값도 역대 가장 높은 수준으로 끌어 올렸습니다. 경제가 불...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\\n[앵커]집값을 잡기 위해 종합부동산세를 올리려던 정부의 계획도 20대 국회에 가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\\n■ 인용보도 시 프로그램명 'JTBC &lt; 아침&amp; &gt;'을 밝혀주시기 바랍니다. 저...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\\n1. 현대·기아차 글로벌 공장 재가동코로나 여파로 한달 넘게 문을 닫았던 현대·...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\n[앵커]사상 처음으로 받는 긴급재난지원금이기 때문에 어떻게 받을지 또 어디에서 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content\n",
       "0   \\n[앵커]정부가 서울 도심에 주택 7만 가구를 짓기로 했습니다. 지지부진한 재개발...\n",
       "1   \\n1. KDI \"2분기 이후 청년고용 충격\"코로나 여파로 인한 청년층 고용 충격이...\n",
       "2   \\n[앵커]이재용 부회장은 10분 동안 미리 준비해온 사과문을 읽었습니다. 두 차례...\n",
       "3   \\n[앵커]이재용 삼성전자 부회장이 어제(6일) 대국민 사과문을 발표했습니다. 경영...\n",
       "4   \\n[앵커]그동안 사회적 거리두기로 집에서 온라인 쇼핑하는 분들이 많았는데요. 어떤...\n",
       "5   \\n[앵커]한때 2~3시간 줄을 서야 살 수 있던 마스크를 요즘엔 기다리지 않아도 ...\n",
       "6   \\n[앵커]정부가 서울 도심에 주택 7만 가구를 짓기로 했습니다. 지지부진한 재개발...\n",
       "7   \\n■ 인용보도 시 프로그램명 'JTBC <뉴스룸>'을 밝혀주시기 바랍니다. 저작권...\n",
       "8   \\n[앵커]이재용 부회장은 10분간 준비해 온 사과문을 읽으며 두 번 고개를 숙였습...\n",
       "9   \\n[앵커]삼성전자 이재용 부회장이 오늘(6일) 대국민 사과문을 발표했습니다. 경영...\n",
       "10  \\n[앵커]이재용 삼성전자 부회장이 경영권 승계와 노조 문제 등과 관련해 대국민 사...\n",
       "11  \\n■ 인용보도 시 프로그램명 'JTBC < 아침& >'을 밝혀주시기 바랍니다. 저...\n",
       "12  \\n[앵커]어제(5일) 마트와 백화점은 쇼핑객들로 종일 붐볐는데요. 소비 심리가 본...\n",
       "13  \\n[앵커]집값을 잡기 위해 종합부동산세를 올리려던 정부의 계획이 20대 국회에 가...\n",
       "14  \\n1. \"지역화폐 바가지 땐 가맹점 박탈\"이재명 경기도지사가 이번에는 재난기본소득...\n",
       "15  \\n[앵커]코로나19는 금값도 역대 가장 높은 수준으로 끌어 올렸습니다. 경제가 불...\n",
       "16  \\n[앵커]집값을 잡기 위해 종합부동산세를 올리려던 정부의 계획도 20대 국회에 가...\n",
       "17  \\n■ 인용보도 시 프로그램명 'JTBC < 아침& >'을 밝혀주시기 바랍니다. 저...\n",
       "18  \\n1. 현대·기아차 글로벌 공장 재가동코로나 여파로 한달 넘게 문을 닫았던 현대·...\n",
       "19  \\n[앵커]사상 처음으로 받는 긴급재난지원금이기 때문에 어떻게 받을지 또 어디에서 ..."
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.DataFrame(news_data,columns=[\"content\"])\n",
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 네이버 블로그 제목 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 영문번역 : 아이유의 새 싱글 \"Eight\"\n",
      "아이유 - 에잇 (Prod. & Feat. SUGA of BTS)\n",
      "① 그래픽 노블 <빌어먹을 세상 따위> : 아이유가 가장...\n",
      "200413 아이유 정은지 가요광장 출퇴근 사진 후기...\n",
      "아이유 에잇(8)\n",
      "아이유 X 방탄소년단 슈가 콜라보 '에잇 Eight' 5월 6일 공개!\n",
      "[IU]아이유 슈가 Eight(feat.SUGA of BTS 듣기 가사♡♡♡\n",
      "<팬텀싱어3> 아이유, 'Love Poem' 안동영 vs. 유채훈\n",
      "아이유,유인나가 선택한 메이크업샵! [멥시]\n",
      "팬텀싱어3_3회 : 아이유 'Love Poem'으로 듣는 인간 드라마...\n",
      "여자 선글라스 추천 아이유도 선택한 베디베로 이쁘닷!\n",
      "아이유 에잇 티저\n",
      "아이유 에잇 기타 코드 (1capo, 쉬운 코드)\n",
      "9년전 추억팔이 아이유 만난 좋은날~!\n",
      "아이유 온라인 스토어 구매 후기\n",
      "간단한아침메뉴 아이유다이어트식단 매일스쿼트 100개\n",
      "아이유 에잇_ Eight(Ft 슈가 BTS) 단상_ 스물여덟 아이유의...\n",
      "언주역 네일, 아이유네일!\n",
      "아이유 신곡 에잇(eigth), 미국 아이튠즈 1위 기록\n",
      "집순이취미 * 카시다칼림바 언박싱, 아이유 blueming 연주...\n",
      "아이유 마음\n",
      "지민 라이브 매력/ 유튜브 온라인 졸업식/슈가 아이유 에잇 대박!\n",
      "속눈썹펌 추천, 영통아이유속눈썹에서 예뻐져요~\n",
      "아이유, 슈가의 콜라보?!!!\n",
      "힘들 때 위로가 되어준 아이유의 말 한마디\n",
      "selfie 2 waifu 절대 하지마세요 (임영웅,아이유,부부의세계...\n",
      "[헤어/메이크업샵] 아이유의 그곳, 멥시\n",
      "[이 우정 대찬성~♥ 5탄] 아이유 & 에이핑크 정은지\n",
      "200322 아이유 구찌를 입다_ 명품 단상(Feat w코리아 비하인드)\n",
      "SuperMan Music - 아이유 하루 끝\n",
      "아이유 또 1000만원 기부ㄷㄷㄷ\n",
      "아이유 : 에잇(Prod.&Feat. SUGA of BTS)\n",
      "아이유x슈가의 콜라보 '에잇' 노래가사 캘리그라피\n",
      "아이유 블루밍 리얼 드럼 연주를 보다!\n",
      "아이유 신곡_에잇_\n",
      "아이유 IU - Blueming[듣기/뮤비/가사]\n",
      "동그란 아이유 안경인 젠틀몬스터 레토\n",
      "방탄소년단, 슈가x아이유 에잇, 뮤비와 가사✨\n",
      "사랑의 불시착 OST 마지막 :) 아이유 - 마음을 드려요~\n",
      "아이유(IU)&방탄소년단(SUGA of BTS) - eight (에잇)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "for i in range(1,40,10):\n",
    "    url = 'https://search.naver.com/search.naver?date_from=&date_option=0&date_to=&dup_remove=1&nso=&post_blogurl=&post_blogurl_without=&query=%EC%95%84%EC%9D%B4%EC%9C%A0&sm=tab_pge&srchby=all&st=sim&where=post&start={}'.format(i)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "    for i in range(10):\n",
    "        print(soup.select(\"#elThumbnailResultArea .sh_blog_top .sh_blog_title\")[i].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 셀리니움으로 유투브 검색후 영상에 들어가기. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "driver = webdriver.Chrome(\"C:/chromedriver\")\n",
    "driver.get(\"https://www.youtube.com/\")\n",
    "\n",
    "input_el = driver.find_element_by_name(\"search_query\")\n",
    "input_el.send_keys(\"아이유\")\n",
    "input_el.send_keys(Keys.RETURN) # 아이유 검색하기 \n",
    "\n",
    "input_content = driver.find_element_by_id(\"video-title\")\n",
    "input_content.click() # 동영상 클릭하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스크롤 내리는 코드 (일일히 눌러야 함.)\n",
    "height =1000\n",
    "driver.execute_script(f\"window.scrollTo(0,{height});\")\n",
    "height += 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스크롤 내리는 코드 (while 문으로 알아서 움직임)\n",
    "\n",
    "import time\n",
    "last_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\") \n",
    "while True: \n",
    "    driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\") \n",
    "    time.sleep(3.0) \n",
    "    new_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\") \n",
    "    if new_page_height == last_page_height: \n",
    "        break \n",
    "    last_page_height = new_page_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노래너무좋아♥️♥️\n",
      "아이유는 인정\n",
      "sub\n",
      "IU es la mejor♥️♥️\n"
     ]
    }
   ],
   "source": [
    "# 댓글을 크롤링하는 코드\n",
    "result_list = driver.find_elements_by_id(\"content-text\")\n",
    "for i in result_list:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선생님 유튜브 댓글 크롤링 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\com\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\com\\anaconda3\\lib\\site-packages (from selenium) (1.25.8)\n",
      "Collecting konlpy\n",
      "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
      "Collecting beautifulsoup4==4.6.0\n",
      "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\com\\anaconda3\\lib\\site-packages (from konlpy) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\com\\anaconda3\\lib\\site-packages (from konlpy) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\com\\anaconda3\\lib\\site-packages (from konlpy) (1.18.1)\n",
      "Collecting JPype1>=0.7.0\n",
      "  Downloading JPype1-0.7.4-cp37-cp37m-win_amd64.whl (1.4 MB)\n",
      "Collecting tweepy>=3.7.0\n",
      "  Downloading tweepy-3.8.0-py2.py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: requests>=2.11.1 in c:\\users\\com\\anaconda3\\lib\\site-packages (from tweepy>=3.7.0->konlpy) (2.22.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in c:\\users\\com\\anaconda3\\lib\\site-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\com\\anaconda3\\lib\\site-packages (from tweepy>=3.7.0->konlpy) (1.14.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\com\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\com\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\com\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\com\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Installing collected packages: beautifulsoup4, JPype1, oauthlib, requests-oauthlib, tweepy, konlpy\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.8.2\n",
      "    Uninstalling beautifulsoup4-4.8.2:\n",
      "      Successfully uninstalled beautifulsoup4-4.8.2\n",
      "Successfully installed JPype1-0.7.4 beautifulsoup4-4.6.0 konlpy-0.5.2 oauthlib-3.1.0 requests-oauthlib-1.3.0 tweepy-3.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "####설정부분####\n",
    "n=6\n",
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common import exceptions\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/chromedriver')\n",
    "driver.get('https://www.youtube.com/watch?v=G3qG3dVZc4o&list=UUzW0FveoY3_sTgBjvpG7Kwg')\n",
    "driver.maximize_window()\n",
    "last_index = 0\n",
    "commentlist=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "0\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "StaleElementReferenceException Occured!\n",
      "\n",
      "None\n",
      "TypeError occured!\n",
      "\n",
      "StaleElementReferenceException Occured!\n",
      "\n"
     ]
    },
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=81.0.4044.129)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-287-286d9cbb8e0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//*[@id=\"icon-label\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m             'value': value})['value']\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"icon-label\"]\"}\n  (Session info: chrome=81.0.4044.129)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-287-286d9cbb8e0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mNoSuchElementException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mpagebody\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPAGE_DOWN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36msend_keys\u001b[1;34m(self, *value)\u001b[0m\n\u001b[0;32m    477\u001b[0m         self._execute(Command.SEND_KEYS_TO_ELEMENT,\n\u001b[0;32m    478\u001b[0m                       {'text': \"\".join(keys_to_typing(value)),\n\u001b[1;32m--> 479\u001b[1;33m                        'value': keys_to_typing(value)})\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# RenderedWebElement Items\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=81.0.4044.129)\n"
     ]
    }
   ],
   "source": [
    "#페이지 우측의 동영상재생목록을 가져온다.\n",
    "time.sleep(2)\n",
    "video_list = driver.find_elements_by_css_selector('#video-title.ytd-playlist-panel-video-renderer')\n",
    "print(len(video_list))\n",
    "\n",
    "#영상목록의 영상에 한개씩 접근해 조건에 맞는 댓글을 수집해온다.\n",
    "for vid in video_list:\n",
    "    try:\n",
    "        vid.click()\n",
    "    #특정 영상에 다음 예외가 발생하는 경우가 있어 예외처리. 댓글은 수집됨.\n",
    "    except StaleElementReferenceException:\n",
    "        print('StaleElementReferenceException Occured!\\n')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #[정렬기준]을 클릭할 수 있을 때까지 페이지다운버튼을 누른다.\n",
    "    #timesleep을 하지 않으면 버튼이 있어도 지나친다.\n",
    "    pagebody = driver.find_element_by_tag_name('body')\n",
    "    while True:\n",
    "        try:\n",
    "            driver.find_element_by_xpath('//*[@id=\"icon-label\"]').click()\n",
    "            break;\n",
    "        except NoSuchElementException:\n",
    "            pagebody.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(1)\n",
    "    \n",
    "    #[최신순]을 눌러 댓글을 최신순정렬한다.\n",
    "    time.sleep(0.5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"menu\"]/a[2]/paper-item/paper-item-body/div[1]').click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    #작성댓글 리스트, 작성시간 리스트를 가져온다.(같은태그로 가져올 수 없음)\n",
    "    comments = driver.find_elements_by_id('content-text')\n",
    "    date_list = driver.find_elements_by_xpath('//*[@id=\"header-author\"]/yt-formatted-string/a')\n",
    "    \n",
    "    #for문으로 조건에 맞는 댓글만 commentlist에 추가\n",
    "    #시간조건을 만족하는 가장 마지막 댓글의 인덱스를 가져와 인덱스까지의 댓글을 수집하도록 함\n",
    "    for d,date in enumerate(date_list):\n",
    "        #시간조건에 따라 가장 처음댓글의 인덱스 지정.\n",
    "        #가장 처음댓글이 'n주 전' 또는 'n개월 전'이면 인덱스==none.\n",
    "        #'n시간전'이면 무조건, 'n일 전'이면 조건에 맞는 댓글의 인덱스를 저장.\n",
    "        if d==0:\n",
    "            if (date.text[1]=='주') or (date.text[1]=='개'):\n",
    "                last_index = None\n",
    "                break;\n",
    "            elif (date.text[1]=='시'):\n",
    "                last_index = d\n",
    "            elif (date.text[1]=='일'):\n",
    "                if int(date.text[0])<= n:\n",
    "                    last_index = d\n",
    "        #시간조건에 따라 첫번째 이후의 댓글의 인덱스 지정.\n",
    "        #n시간전'이면 무조건, 'n일 전'이면 조건에 맞는 댓글의 인덱스를 저장.\n",
    "        #n일을 초과하는 경우 break;로 빠져나와 이전의 인덱스를 저장하고 있음\n",
    "        elif d!=0:\n",
    "            if (date.text[1]=='시'):\n",
    "                last_index = d\n",
    "            elif (date.text[1]=='일'):\n",
    "                if int(date.text[0])<= n:\n",
    "                    last_index = d\n",
    "                else:\n",
    "                    break;\n",
    "            else:\n",
    "                break;\n",
    "    print(last_index)\n",
    "    \n",
    "    #저장한 인덱스까지의 댓글을 리스트에 추가함\n",
    "    try:\n",
    "        for i,c in enumerate(comments):\n",
    "            if(i<=last_index):\n",
    "                commentlist.append(c.text) \n",
    "            else:\n",
    "                break;\n",
    "    #시간조건을 만족하는 댓글이 하나도 없어 인덱스가 None인경우 TypeError가 발생하며 아무댓글도 추가되지 않음\n",
    "    except TypeError:\n",
    "        print('TypeError occured!\\n')\n",
    "            \n",
    "    time.sleep(0.1)\n",
    "    driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['주로 중고신입이 합격하나요 ㅠㅠ  석사직이라 그런건가  ㄷㄷ']"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#숫자와 문자만 따로 빼서 저장(특수문자 및 이모티콘 제외)\n",
    "import re\n",
    "cmt_lst=[]\n",
    "for i in commentlist:\n",
    "    i = re.sub('[^0-9a-zA-Zㄱ-힗]', ' ', i)\n",
    "    cmt_lst.append(i)\n",
    "cmt_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>주로 중고신입이 합격하나요 ㅠㅠ  석사직이라 그런건가  ㄷㄷ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             comment\n",
       "0  주로 중고신입이 합격하나요 ㅠㅠ  석사직이라 그런건가  ㄷㄷ"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터프레임으로 만들어 파일로 저장\n",
    "import pandas as pd\n",
    "comment_df=pd.DataFrame({'comment':cmt_lst})\n",
    "comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
