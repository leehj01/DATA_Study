{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "\n",
    "- CNN 은 합성곱이라고 함.\n",
    "- 합성곱은 하나의 함수와 다른 함수를 반전, 이동 한 값을 곱한 후에 가 국간을 적분하여 새로운 함수를 만드는 연산자\n",
    "- 필터처리 \n",
    "- 계층 \n",
    "    - 합성곱 계층\n",
    "        - 영상의 특징을 추출하기 위한 계층\n",
    "        - 합성곱 계층의 입력 영상은 필터를 거치게 됨\n",
    "        \n",
    "    - 풀링 계층\n",
    "    \n",
    "- 필터 커널  (인공신경망에서는 필터를 자기가 알아서 만들어줌) \n",
    "    - 원 영상\n",
    "    - sharpen 필터 : 조금 느낌이 날카롭다.\n",
    "    - box blur : 흐릿하게 \n",
    "    - gaussian blur : 흐릿하지만, 윤곽선은 덜 흐릿하게 하는 것\n",
    "    - 윤곽선을 찾아 내는 필터(윤곽선 검출) - 엣쥐 무슨 필터 \n",
    "    \n",
    "- 제로 패딩 : 주변에 있는애들은 계산이 다 안되기 때문에 0 이 된다. \n",
    "\n",
    "- 맥스 풀링 (max pooling) : 이미지가 4분의1 로 줄어듦. 그래도 모양이 이상해 지지않음\n",
    "    - 원영상과 달라질수도 있지만, 특징 이미지가 만들어지고 그 특징 이미지가 학습만 잘 되기만 하면 됨. \n",
    "    - 여기서는 feachure 뽑는것을 ai가 알아서 함.\n",
    "- 민 풀링(mean pooling) \n",
    "\n",
    "\n",
    "=> 이렇게 찾아지는 cnn 을 dnn 에 넣어줌 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 모델 구하기  -  가능한 외우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape : (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:From C:\\Users\\COM\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 25s 421us/sample - loss: 2.3204 - acc: 0.0980 - val_loss: 2.2976 - val_acc: 0.1174\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 24s 397us/sample - loss: 2.2971 - acc: 0.1159 - val_loss: 2.2756 - val_acc: 0.1802\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 2.2773 - acc: 0.1388 - val_loss: 2.2544 - val_acc: 0.2929\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 2.2569 - acc: 0.1673 - val_loss: 2.2330 - val_acc: 0.3791\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 23s 390us/sample - loss: 2.2375 - acc: 0.1963 - val_loss: 2.2102 - val_acc: 0.4419\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 2.2157 - acc: 0.2256 - val_loss: 2.1853 - val_acc: 0.5007\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 2.1930 - acc: 0.2551 - val_loss: 2.1581 - val_acc: 0.5458\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 2.1677 - acc: 0.2835 - val_loss: 2.1283 - val_acc: 0.5775\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 24s 392us/sample - loss: 2.1413 - acc: 0.3101 - val_loss: 2.0958 - val_acc: 0.6089\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 25s 417us/sample - loss: 2.1119 - acc: 0.3336 - val_loss: 2.0604 - val_acc: 0.6312\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 24s 395us/sample - loss: 2.0810 - acc: 0.3559 - val_loss: 2.0218 - val_acc: 0.6528\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 2.0455 - acc: 0.3786 - val_loss: 1.9794 - val_acc: 0.6682\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 2.0087 - acc: 0.4012 - val_loss: 1.9337 - val_acc: 0.6798\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 1.9682 - acc: 0.4199 - val_loss: 1.8844 - val_acc: 0.6903\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 1.9281 - acc: 0.4360 - val_loss: 1.8322 - val_acc: 0.6998\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 1.8840 - acc: 0.4527 - val_loss: 1.7772 - val_acc: 0.7101\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 1.8386 - acc: 0.4676 - val_loss: 1.7198 - val_acc: 0.7208\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 1.7946 - acc: 0.4789 - val_loss: 1.6608 - val_acc: 0.7307\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 1.7474 - acc: 0.4933 - val_loss: 1.6008 - val_acc: 0.7425\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 1.6991 - acc: 0.5056 - val_loss: 1.5402 - val_acc: 0.7500\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 1.6512 - acc: 0.5188 - val_loss: 1.4801 - val_acc: 0.7570\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 1.6058 - acc: 0.5290 - val_loss: 1.4208 - val_acc: 0.7639\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 1.5628 - acc: 0.5405 - val_loss: 1.3633 - val_acc: 0.7714\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 1.5171 - acc: 0.5509 - val_loss: 1.3072 - val_acc: 0.7766\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 23s 389us/sample - loss: 1.4774 - acc: 0.5618 - val_loss: 1.2538 - val_acc: 0.7843\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 1.4384 - acc: 0.5667 - val_loss: 1.2028 - val_acc: 0.7899\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 1.3979 - acc: 0.5784 - val_loss: 1.1542 - val_acc: 0.7951\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 1.3624 - acc: 0.5904 - val_loss: 1.1080 - val_acc: 0.8001\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 23s 388us/sample - loss: 1.3216 - acc: 0.5995 - val_loss: 1.0637 - val_acc: 0.8057\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 1.2888 - acc: 0.6086 - val_loss: 1.0225 - val_acc: 0.8101\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 1.2602 - acc: 0.6150 - val_loss: 0.9842 - val_acc: 0.8153\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 1.2263 - acc: 0.6257 - val_loss: 0.9483 - val_acc: 0.8192\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 1.1930 - acc: 0.6316 - val_loss: 0.9139 - val_acc: 0.8235\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 1.1708 - acc: 0.6395 - val_loss: 0.8825 - val_acc: 0.8279\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 1.1473 - acc: 0.6441 - val_loss: 0.8532 - val_acc: 0.8312\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 1.1159 - acc: 0.6543 - val_loss: 0.8252 - val_acc: 0.8354\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 1.0929 - acc: 0.6599 - val_loss: 0.7988 - val_acc: 0.8379\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 1.0688 - acc: 0.6676 - val_loss: 0.7742 - val_acc: 0.8405\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 1.0517 - acc: 0.6733 - val_loss: 0.7514 - val_acc: 0.8442\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 24s 394us/sample - loss: 1.0262 - acc: 0.6811 - val_loss: 0.7293 - val_acc: 0.8472\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 24s 394us/sample - loss: 1.0093 - acc: 0.6850 - val_loss: 0.7090 - val_acc: 0.8511\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 24s 397us/sample - loss: 0.9866 - acc: 0.6905 - val_loss: 0.6894 - val_acc: 0.8537\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 23s 388us/sample - loss: 0.9708 - acc: 0.6945 - val_loss: 0.6715 - val_acc: 0.8555\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.9551 - acc: 0.7007 - val_loss: 0.6544 - val_acc: 0.8583\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.9366 - acc: 0.7038 - val_loss: 0.6381 - val_acc: 0.8613\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.9224 - acc: 0.7087 - val_loss: 0.6229 - val_acc: 0.8630\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.9022 - acc: 0.7175 - val_loss: 0.6080 - val_acc: 0.8657\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.8885 - acc: 0.7188 - val_loss: 0.5942 - val_acc: 0.8674\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.8772 - acc: 0.7229 - val_loss: 0.5807 - val_acc: 0.8696\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.8620 - acc: 0.7313 - val_loss: 0.5683 - val_acc: 0.8711\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.8502 - acc: 0.7340 - val_loss: 0.5568 - val_acc: 0.8730\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.8384 - acc: 0.7339 - val_loss: 0.5457 - val_acc: 0.8748\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.8221 - acc: 0.7405 - val_loss: 0.5347 - val_acc: 0.8771\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.8116 - acc: 0.7442 - val_loss: 0.5242 - val_acc: 0.8782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.8021 - acc: 0.7465 - val_loss: 0.5145 - val_acc: 0.8799\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.7884 - acc: 0.7508 - val_loss: 0.5044 - val_acc: 0.8814\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.7827 - acc: 0.7533 - val_loss: 0.4955 - val_acc: 0.8833\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.7693 - acc: 0.7579 - val_loss: 0.4869 - val_acc: 0.8849\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.7584 - acc: 0.7606 - val_loss: 0.4786 - val_acc: 0.8859\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.7532 - acc: 0.7620 - val_loss: 0.4707 - val_acc: 0.8876\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.7415 - acc: 0.7660 - val_loss: 0.4632 - val_acc: 0.8887\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.7366 - acc: 0.7679 - val_loss: 0.4558 - val_acc: 0.8915\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.7254 - acc: 0.7717 - val_loss: 0.4488 - val_acc: 0.8929\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.7135 - acc: 0.7766 - val_loss: 0.4418 - val_acc: 0.8941\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.7081 - acc: 0.7770 - val_loss: 0.4351 - val_acc: 0.8951\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.6997 - acc: 0.7800 - val_loss: 0.4288 - val_acc: 0.8960\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.6903 - acc: 0.7833 - val_loss: 0.4226 - val_acc: 0.8977\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.6796 - acc: 0.7867 - val_loss: 0.4163 - val_acc: 0.8991\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.6782 - acc: 0.7867 - val_loss: 0.4108 - val_acc: 0.9002\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.6687 - acc: 0.7910 - val_loss: 0.4053 - val_acc: 0.9005\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.6598 - acc: 0.7941 - val_loss: 0.3999 - val_acc: 0.9013\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.6510 - acc: 0.7955 - val_loss: 0.3944 - val_acc: 0.9028\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.6472 - acc: 0.7980 - val_loss: 0.3895 - val_acc: 0.9036\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.6437 - acc: 0.7978 - val_loss: 0.3847 - val_acc: 0.9044\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.6347 - acc: 0.8012 - val_loss: 0.3800 - val_acc: 0.9058\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.6335 - acc: 0.8006 - val_loss: 0.3755 - val_acc: 0.9067\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.6204 - acc: 0.8066 - val_loss: 0.3710 - val_acc: 0.9074\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.6160 - acc: 0.8064 - val_loss: 0.3664 - val_acc: 0.9088\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 23s 391us/sample - loss: 0.6064 - acc: 0.8101 - val_loss: 0.3623 - val_acc: 0.9092\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 23s 389us/sample - loss: 0.6056 - acc: 0.8100 - val_loss: 0.3582 - val_acc: 0.9105\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.6032 - acc: 0.8123 - val_loss: 0.3546 - val_acc: 0.9111\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.5940 - acc: 0.8134 - val_loss: 0.3506 - val_acc: 0.9118\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.5895 - acc: 0.8150 - val_loss: 0.3467 - val_acc: 0.9122\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.5852 - acc: 0.8182 - val_loss: 0.3433 - val_acc: 0.9128\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.5810 - acc: 0.8208 - val_loss: 0.3395 - val_acc: 0.9136\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.5765 - acc: 0.8193 - val_loss: 0.3361 - val_acc: 0.9140\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.5683 - acc: 0.8249 - val_loss: 0.3326 - val_acc: 0.9154\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 23s 386us/sample - loss: 0.5643 - acc: 0.8264 - val_loss: 0.3293 - val_acc: 0.9163\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 24s 396us/sample - loss: 0.5565 - acc: 0.8261 - val_loss: 0.3258 - val_acc: 0.9169\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 24s 400us/sample - loss: 0.5537 - acc: 0.8272 - val_loss: 0.3224 - val_acc: 0.9179\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 24s 399us/sample - loss: 0.5494 - acc: 0.8292 - val_loss: 0.3193 - val_acc: 0.9181\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 24s 401us/sample - loss: 0.5424 - acc: 0.8316 - val_loss: 0.3163 - val_acc: 0.9185\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 25s 416us/sample - loss: 0.5425 - acc: 0.8306 - val_loss: 0.3138 - val_acc: 0.9194\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 25s 413us/sample - loss: 0.5367 - acc: 0.8317 - val_loss: 0.3107 - val_acc: 0.9204\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 24s 407us/sample - loss: 0.5335 - acc: 0.8342 - val_loss: 0.3079 - val_acc: 0.9208\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 25s 409us/sample - loss: 0.5296 - acc: 0.8359 - val_loss: 0.3052 - val_acc: 0.9207\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 25s 412us/sample - loss: 0.5216 - acc: 0.8388 - val_loss: 0.3023 - val_acc: 0.9217\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 25s 409us/sample - loss: 0.5194 - acc: 0.8386 - val_loss: 0.2996 - val_acc: 0.9222\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 25s 410us/sample - loss: 0.5180 - acc: 0.8395 - val_loss: 0.2972 - val_acc: 0.9225\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 25s 409us/sample - loss: 0.5119 - acc: 0.8421 - val_loss: 0.2948 - val_acc: 0.9234\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "(x_train,y_train), (x_test, y_test)  = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1)\n",
    "\n",
    "x_train= x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255 # 225로 나눴는데, 표준화 하지 않아도 됨\n",
    "x_test /= 255\n",
    "\n",
    "print(\"x_train shape :\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0],\"test samples\" )\n",
    "\n",
    "\n",
    "#convert class vectors to binary cflass matrices\n",
    "\n",
    "y_train =tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test= tf.keras.utils.to_categorical(y_test, 10) \n",
    "# 원핫 인코딩 해야, 값을 비교할 수 있음  \n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3), # kernel_size =(3,3)\n",
    "               input_shape=(28,28,1),activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size= (2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size= (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "model.compile(loss = tf.keras.losses.categorical_crossentropy,\n",
    "             optimizer = tf.keras.optimizers.Adadelta(), metrics=[\"accuracy\"])\n",
    "\n",
    "hist = model.fit(x_train, y_train, validation_data= (x_test, y_test),\n",
    "                 batch_size =128, epochs =100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mnist_keras_model_.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\COM\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\COM\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"mnist_keras_model_.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test losee: 0.2947762266755104\n",
      "test acccuracy: 0.9234\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print(\"test losee:\",score[0])\n",
    "print(\"test acccuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 21s 353us/sample - loss: 0.5092 - acc: 0.8421 - val_loss: 0.2940 - val_acc: 0.9235\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 22s 359us/sample - loss: 0.5109 - acc: 0.8422 - val_loss: 0.2933 - val_acc: 0.9239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xf6bea88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미 학습된 것에 다시 학습시키기\n",
    "\n",
    "model.fit(x_train, y_train, validation_data= (x_test, y_test),\n",
    "                 batch_size =500, epochs = 2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test losee: 0.29331231755018233\n",
      "test acccuracy: 0.9239\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print(\"test losee:\",score[0])\n",
    "print(\"test acccuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  학습한것을 그림으로 나타내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b52e9fb56d55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"train_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtwinx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'g'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], 'y', label = \"train_loss\")\n",
    "plt.plot(history.history['val_loss'], 'r', label = \"val_loss\")\n",
    "ax = plt.twinx()\n",
    "ax.plot(history.history[\"acc\"],'g',label=\"train_acc\")\n",
    "ax.plot(history.history['val_acc'], 'b', label = \"val_loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backend\n",
    "- 디테일하게 구현하고 싶은 것이 있다며 backend 를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as k\n",
    "\n",
    "def recall(y_target, y_pred):    \n",
    "    y_target_yn = k.round(k.clip(y_target,0,1) #실제값을 0 또는 1로 설정한다.\n",
    "    y_pred_yn = k.round(k.clip(y_pred , 0,1 )) # 예측값을 0또는 1로 설정한다.\n",
    "                          \n",
    "    # True Positive는 실제 값과 예측 값이 모두 1 인 경우\n",
    "    count_true_positive = k.sum(y_target_yn * y_pred_yn)\n",
    "                          \n",
    "    # (true positive + false negative) = 실제값이 1 전체\n",
    "  count_true_positive_false_negative = k.sum(y_target_yn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as k\n",
    "\n",
    "def recall(y_target, y_pred):\n",
    "    y_target_yn = k.round(k.clip(y_target,0,1)) #실제값을 0 또는 1로 설정한다.\n",
    "    y_pred_yn = k.round(k.clip(y_pred,0,1 )) # 예측값을 0또는 1로 설정한다.\n",
    "                          \n",
    "    # True Positive는 실제 값과 예측 값이 모두 1 인 경우\n",
    "    count_true_positive = k.sum(y_target_yn * y_pred_yn)\n",
    "                          \n",
    "    # (true positive + false negative) = 실제값이 1 전체\n",
    "    count_true_positive_false_negative = k.sum(y_target_yn)\n",
    "                          \n",
    "    # recall = (true positive) / (true positive + false negative)\n",
    "    # k.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / ( count_true_positive_false_negative + k.epsilon())\n",
    "\n",
    "    # return a single tensor value \n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(loss=categorical_crossentropy, optimizer= Adam(0.0002), metrics = [\"accuracy\", recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 22s 366us/sample - loss: 0.4018 - acc: 0.8764 - recall: 0.8364 - val_loss: 0.1723 - val_acc: 0.9489 - val_recall: 0.9354\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 21s 357us/sample - loss: 0.2774 - acc: 0.9172 - recall: 0.8952 - val_loss: 0.1256 - val_acc: 0.9616 - val_recall: 0.9540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x212e8488>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data= (x_test, y_test),\n",
    "                 batch_size =500, epochs = 2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
