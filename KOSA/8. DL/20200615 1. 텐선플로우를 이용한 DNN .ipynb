{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "weight 는 옵티마이저를 이용해서 바뀐다.\n",
    "옵티마이저는 맨마지막에 실행하고 이것이 다시 웨이트를 재조정함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN ( 딥뉴얼 네트워크)\n",
    "#### 은닉층을 가지지 않는 인공신경망을 가지고 , 분류를 하는 모델\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, 1.79176\n",
      "step 10000, 1.08176\n",
      "step 20000, 1.05125\n",
      "step 30000, 1.03211\n",
      "step 40000, 1.01921\n",
      "step 50000, 1.01002\n",
      "step 60000, 1.00318\n",
      "step 70000, 0.99788\n",
      "step 80000, 0.99364\n",
      "step 90000, 0.99014\n",
      "step 100000, 0.98717\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "redwine = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "redwine_x= redwine.iloc[:,:-1]\n",
    "redwine_y = redwine.iloc[:,-1]\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(redwine_y.to_numpy().reshape(-1,1))\n",
    "\n",
    "y_onehot = enc.transform(redwine_y.to_numpy().reshape(-1,1))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x , test_x, train_y, test_y = train_test_split(redwine_x, y_onehot,test_size = 0.3, random_state = 1)\n",
    "\n",
    "x = tf.placeholder (tf.float32, [None, 11])\n",
    "y = tf.placeholder(tf.float32, [None, 6])  # y 의 클래스가 6이다\n",
    "\n",
    "w = tf.Variable(tf.zeros([11,6]))\n",
    "b = tf.Variable(tf.zeros([6]))\n",
    "h = tf.nn.softmax(tf.matmul(x,w)+b)  # 출력 예측한 값\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y * tf.log(h), reduction_indices = [1])\n",
    "\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "training = tf.train.GradientDescentOptimizer(0.001).minimize(loss)  # 손실을 최소화하는 방향으로 학습해주세요.\n",
    "# graident 대신에 아담 옵티마이저를 넣을 수 있다. \n",
    "\n",
    "\n",
    "# 위에 있는애들은 operation \n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(100001):\n",
    "    _, loss_value = sess.run([training, loss], feed_dict= {x : train_x, y : train_y.toarray()})\n",
    "    \n",
    "    # loss 는 출력을 해보려고 써넣음. [] 안에 있는 것을 두개의 값으로 반환하겠다는 뜻이며,\n",
    "    # _ 는 그냥 그 값을 버리겠다는 뜻이다. \n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "        print(\"step %d, %.5f\" % (i, loss_value))\n",
    "        \n",
    "        # 만번에 한번씩, i 와 손실을 출력하기. 손실은 작을 수록 좋음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>151</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68</td>\n",
       "      <td>118</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    5    6  7\n",
       "row_0             \n",
       "3        2    0  0\n",
       "4       12    9  0\n",
       "5      151   54  2\n",
       "6       68  118  9\n",
       "7        4   40  8\n",
       "8        0    1  2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = sess.run(h, feed_dict= {x:test_x})  # 최종적으로h 를 계산하는 것은. 최종적인 값이다.\n",
    "pd.crosstab(np.argmax(test_y.toarray(), axis = 1)+3,\n",
    "           np.argmax(pred, axis=1)+3)\n",
    "\n",
    "\n",
    "# y 가 3등급부터 8등급까지 있는데, 원핫인코딩하면 이 숫자의 의미가 사라지고, 6개열을 가지는 2차원 배열을 만들어짐. \n",
    "# 그중에서 몇등급을 알고싶으면 인덱스를 뽑아내는데, 그 인덱스를 뽑아내는 것이 argmax 임. \n",
    "# 인덱스는 0 부터 나오지만, 등급은 3 등급부터 있기때문에 이 자료에서는 이 등급에서 +3을 해줘야한다. \n",
    "# 즉 , 사실은 3,4,5,6,7,8,등급이다 라는 뜻이당. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5770833333333333"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(np.argmax(test_y.toarray(), axis = 1),\n",
    "              np.argmax(pred, axis =1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 은닉층 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, 1.79176\n",
      "step 10000, 1.25482\n",
      "step 20000, 1.21419\n",
      "step 30000, 1.20277\n",
      "step 40000, 1.19811\n",
      "step 50000, 1.19584\n",
      "step 60000, 1.19455\n",
      "step 70000, 1.19367\n",
      "step 80000, 1.19282\n",
      "step 90000, 1.18958\n",
      "step 100000, 1.17309\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "redwine = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "redwine_x= redwine.iloc[:,:-1]\n",
    "redwine_y = redwine.iloc[:,-1]\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(redwine_y.to_numpy().reshape(-1,1))\n",
    "\n",
    "y_onehot = enc.transform(redwine_y.to_numpy().reshape(-1,1))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x , test_x, train_y, test_y = train_test_split(redwine_x, y_onehot,test_size = 0.3, random_state = 1)\n",
    "\n",
    "x = tf.placeholder (tf.float32, [None, 11])\n",
    "y = tf.placeholder(tf.float32, [None, 6]) \n",
    "\n",
    "\n",
    "w1 = tf.Variable(tf.zeros([11,20]))\n",
    "b1 = tf.Variable(tf.zeros([20]))\n",
    "h1 = tf.nn.relu(tf.matmul(x,w1)+b1)  # relu 말고 다른 활성화 변수를 넣어줘도 가능 \n",
    "\n",
    "w2 = tf.Variable(tf.zeros([20,6]))\n",
    "b2 = tf.Variable(tf.zeros([6]))\n",
    "h = tf.nn.softmax(tf.matmul(h1,w2)+b2)  # 출력 예측한 값\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y * tf.log(h), reduction_indices = [1])\n",
    "\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "training = tf.train.GradientDescentOptimizer(0.001).minimize(loss)  # 손실을 최소화하는 방향으로 학습해주세요.\n",
    "\n",
    "# 위에 있는애들은 operation \n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(100001):\n",
    "    _, loss_value = sess.run([training, loss], feed_dict= {x : train_x, y : train_y.toarray()})\n",
    "    \n",
    "    # loss 는 출력을 해보려고 써넣음. [] 안에 있는 것을 두개의 값으로 반환하겠다는 뜻이며,\n",
    "    # _ 는 그냥 그 값을 버리겠다는 뜻이다. \n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "        print(\"step %d, %.5f\" % (i, loss_value))\n",
    "        \n",
    "        # 만번에 한번씩, i 와 손실을 출력하기. 손실은 작을 수록 좋음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    2\n",
       "row_0     \n",
       "0        2\n",
       "1       21\n",
       "2      207\n",
       "3      195\n",
       "4       52\n",
       "5        3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = sess.run(h, feed_dict= {x:test_x})  # 최종적으로h 를 계산하는 것은. 최종적인 값이다.\n",
    "pd.crosstab(np.argmax(test_y.toarray(), axis = 1),\n",
    "           np.argmax(pred, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43125"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(np.argmax(test_y.toarray(), axis = 1),\n",
    "              np.argmax(pred, axis =1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 히든레이어 하나 더 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, 1.79176\n",
      "step 10000, 1.19649\n",
      "step 20000, 1.19297\n",
      "step 30000, 1.19237\n",
      "step 40000, 1.19221\n",
      "step 50000, 1.19215\n",
      "step 60000, 1.19213\n",
      "step 70000, 1.19212\n",
      "step 80000, 1.19212\n",
      "step 90000, 1.19212\n",
      "step 100000, 1.19212\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "redwine = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "redwine_x= redwine.iloc[:,:-1]\n",
    "redwine_y = redwine.iloc[:,-1]\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(redwine_y.to_numpy().reshape(-1,1))\n",
    "\n",
    "y_onehot = enc.transform(redwine_y.to_numpy().reshape(-1,1))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x , test_x, train_y, test_y = train_test_split(redwine_x, y_onehot,test_size = 0.3, random_state = 1)\n",
    "\n",
    "x = tf.placeholder (tf.float32, [None, 11])\n",
    "y = tf.placeholder(tf.float32, [None, 6]) \n",
    "\n",
    "\n",
    "w1 = tf.Variable(tf.zeros([11,20]))\n",
    "b1 = tf.Variable(tf.zeros([20]))\n",
    "h1 = tf.nn.relu(tf.matmul(x,w1)+b1)  # relu 말고 다른 활성화 변수를 넣어줘도 가능  sigmoid 가능 \n",
    "\n",
    "w2 = tf.Variable(tf.zeros([20,15]))\n",
    "b2 = tf.Variable(tf.zeros([15]))\n",
    "h2 = tf.nn.sigmoid(tf.matmul(h1,w2)+b2)  # 출력 예측한 값\n",
    "\n",
    "w3 = tf.Variable(tf.zeros([15,6]))\n",
    "b3 = tf.Variable(tf.zeros([6]))\n",
    "h = tf.nn.softmax(tf.matmul(h2,w3)+b3)  # 출력 예측한 값\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y * tf.log(h), reduction_indices = [1])\n",
    "\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "training = tf.train.GradientDescentOptimizer(0.001).minimize(loss)  # 손실을 최소화하는 방향으로 학습해주세요.\n",
    "\n",
    "# 위에 있는애들은 operation \n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(100001):\n",
    "    _, loss_value = sess.run([training, loss], feed_dict= {x : train_x, y : train_y.toarray()})\n",
    "    \n",
    "    # loss 는 출력을 해보려고 써넣음. [] 안에 있는 것을 두개의 값으로 반환하겠다는 뜻이며,\n",
    "    # _ 는 그냥 그 값을 버리겠다는 뜻이다. \n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "        print(\"step %d, %.5f\" % (i, loss_value))\n",
    "        \n",
    "        # 만번에 한번씩, i 와 손실을 출력하기. 손실은 작을 수록 좋음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    2\n",
       "row_0     \n",
       "0        2\n",
       "1       21\n",
       "2      207\n",
       "3      195\n",
       "4       52\n",
       "5        3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = sess.run(h, feed_dict= {x:test_x})  # 최종적으로h 를 계산하는 것은. 최종적인 값이다.\n",
    "pd.crosstab(np.argmax(test_y.toarray(), axis = 1),\n",
    "           np.argmax(pred, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43125"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(np.argmax(test_y.toarray(), axis = 1),\n",
    "              np.argmax(pred, axis =1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
