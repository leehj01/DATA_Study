{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN을 이용한 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:16:21.454347Z",
     "start_time": "2020-07-08T01:16:21.300941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2000)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "img = cv2.imread(\"digits.png\", cv2.IMREAD_GRAYSCALE)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:23:05.301017Z",
     "start_time": "2020-07-08T01:23:05.216413Z"
    }
   },
   "outputs": [],
   "source": [
    "cells = [np.hsplit(row , 100) for row in np.vsplit(img,50)]\n",
    "x = np.array(cells) / 255. # 0과 1사이에 하기 위해서 255를 난눠줌. cells 는 0과 255사이에 있기 때문에\n",
    "X = x[:,:].reshape(-1,400).astype(np.float32)\n",
    "y= pd.get_dummies(np.repeat(np.arange(10),500)).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:23:08.888118Z",
     "start_time": "2020-07-08T01:23:08.475508Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x , test_x , train_y, test_y = train_test_split(X, y,test_size= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:23:12.177065Z",
     "start_time": "2020-07-08T01:23:12.141063Z"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 400])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:23:15.394981Z",
     "start_time": "2020-07-08T01:23:15.363781Z"
    }
   },
   "outputs": [],
   "source": [
    "# 어제는 0으로 웨이트를 초기화해줌 \n",
    "# 이코드는 표준편차가 0.1 인 난수를 발생시켜주세요 라고 하는 것. \n",
    "\n",
    "w1 = tf.Variable(tf.truncated_normal([400,512], stddev = 0.1))  \n",
    "b1 = tf.Variable(tf.constant(0.1, shape = [512]))\n",
    "h1 = tf.nn.relu(tf.matmul(x,w1)+b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:23:18.596897Z",
     "start_time": "2020-07-08T01:23:18.581297Z"
    }
   },
   "outputs": [],
   "source": [
    "w2 =tf.Variable(tf.truncated_normal([512,256], stddev = 0.1))  \n",
    "b2 =  tf.Variable(tf.constant(0.1, shape = [256]))\n",
    "h2 = tf.nn.relu(tf.matmul(h1,w2)+b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:23:36.195152Z",
     "start_time": "2020-07-08T01:23:36.157551Z"
    }
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.zeros([256,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:23:39.377795Z",
     "start_time": "2020-07-08T01:23:39.362195Z"
    }
   },
   "outputs": [],
   "source": [
    "h = tf.nn.softmax(tf.matmul(h2,w)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:23:42.524030Z",
     "start_time": "2020-07-08T01:23:42.508430Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_entropy =-tf.reduce_sum(y*tf.log(h), reduction_indices=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:23:45.651713Z",
     "start_time": "2020-07-08T01:23:45.646713Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(cross_entropy)  # 손실 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:24:08.355587Z",
     "start_time": "2020-07-08T01:24:08.264982Z"
    }
   },
   "outputs": [],
   "source": [
    "# 0.5 는 학습률을 의미 \n",
    "train = tf.train.GradientDescentOptimizer(0.5).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:24:23.561743Z",
     "start_time": "2020-07-08T01:24:23.523741Z"
    }
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T02:54:14.849536Z",
     "start_time": "2020-07-08T02:53:20.609262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, train loss 2.087545116784681e-05\n",
      "step 100, train loss 1.996832920400159e-05\n",
      "step 200, train loss 1.913346846670131e-05\n",
      "step 300, train loss 1.8360909641213604e-05\n",
      "step 400, train loss 1.764402446390116e-05\n",
      "step 500, train loss 1.6979918227126988e-05\n",
      "step 600, train loss 1.6359490098907638e-05\n",
      "step 700, train loss 1.5781950798341044e-05\n",
      "step 800, train loss 1.5241040781641939e-05\n",
      "step 900, train loss 1.4732621954916631e-05\n",
      "016 - 0.000004\r"
     ]
    }
   ],
   "source": [
    "tot_cnt = len(train_x)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    avg_loss = 0\n",
    "    batch_size = 200\n",
    "    tot_iter = int(tot_cnt / batch_size)\n",
    "    for step in range(tot_iter):\n",
    "        batch_X = train_x[int(step*batch_size):int((step+1)*batch_size)]\n",
    "        batch_y = train_y[int(step*batch_size):int((step+1)*batch_size)]\n",
    "        _, loss_ = sess.run([train, loss], feed_dict={x:batch_X, y:batch_y})\n",
    "        avg_loss += (loss_ / tot_iter)\n",
    "        print(\"{:03d} - {:f}\".format(step, loss_), end=\"\\r\")\n",
    "    if len(train_x)//tot_iter != 0:\n",
    "        batch_X = train_x[int(tot_iter*batch_size):]\n",
    "        batch_y = train_y[int(tot_iter*batch_size):]\n",
    "        _, loss_ = sess.run([train, loss], feed_dict={x:batch_X, y:batch_y})\n",
    "        avg_loss += (loss_ / tot_iter)\n",
    "        print(\"{:03d} - {:f}\".format(step, loss_), end=\"\\r\")\n",
    "    if epoch%100 ==0:\n",
    "        print(\"step {}, train loss {}\".format(epoch, avg_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T02:13:58.661243Z",
     "start_time": "2020-07-08T02:13:58.614241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.944\n"
     ]
    }
   ],
   "source": [
    "# 예측해보기\n",
    "correct_prediction = tf.equal(tf.argmax(h,1), tf.argmax(y,1)) # 1 은 축을 의미함\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x:test_x,y:test_y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T02:14:01.945431Z",
     "start_time": "2020-07-08T02:14:01.934430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.60679151e-05 3.12727647e-14 1.92031008e-03 1.08969934e-11\n",
      "  2.64617213e-12 1.37196015e-08 9.98043537e-01 3.67975615e-13\n",
      "  2.13918249e-12 1.17265878e-15]\n",
      " [1.17145821e-10 9.99995947e-01 5.72371164e-07 7.28954050e-11\n",
      "  3.33894086e-08 1.48374868e-10 2.30492310e-06 1.69613195e-08\n",
      "  1.23087352e-06 4.68823250e-14]\n",
      " [2.97887088e-16 1.50920130e-08 3.32287149e-13 3.61405350e-11\n",
      "  9.99946356e-01 2.84389751e-11 3.63215014e-12 1.52481927e-09\n",
      "  5.35904292e-05 5.09354736e-09]\n",
      " [1.62699577e-17 1.05216552e-14 2.38997546e-14 7.30494936e-15\n",
      "  1.00000000e+00 3.78292997e-09 1.91704161e-12 2.01976090e-13\n",
      "  2.64013394e-10 2.18059544e-08]\n",
      " [1.11491560e-09 5.29078825e-08 4.65063116e-04 1.11223508e-09\n",
      "  7.30984651e-09 1.36111344e-08 9.99534249e-01 1.26094718e-10\n",
      "  5.61115144e-07 1.55170096e-11]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(h, feed_dict={x:test_x})[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:27:15.246029Z",
     "start_time": "2020-07-08T01:27:15.214829Z"
    }
   },
   "source": [
    "- 그래딘티 베니싱 ? 문제 해결하려면\n",
    "- 배치 정규화\n",
    "- 웨이트를 0,1, 이아닌 다른 것을 초기화한다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:28:57.847394Z",
     "start_time": "2020-07-08T01:28:57.779192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 1 4 ... 3 8 9]\n"
     ]
    }
   ],
   "source": [
    "predict_y = sess.run(tf.argmax(h,1),feed_dict={x:test_x})\n",
    "print(predict_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:29:01.069458Z",
     "start_time": "2020-07-08T01:29:01.053858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 4 4 6 4 7 8 9 6 1 3 5 5 0 0 7 0 9 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_y.argmax(axis=1)[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T01:27:28.055609Z",
     "start_time": "2020-07-08T01:27:27.936404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>148</td>\n",
       "      <td>151</td>\n",
       "      <td>135</td>\n",
       "      <td>150</td>\n",
       "      <td>148</td>\n",
       "      <td>160</td>\n",
       "      <td>152</td>\n",
       "      <td>148</td>\n",
       "      <td>158</td>\n",
       "      <td>150</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1    2    3    4    5    6    7    8    9   All\n",
       "row_0                                                        \n",
       "0      142    0    0    1    0    1    0    0    0    0   144\n",
       "1        0  150    4    1    0    0    0    1    0    0   156\n",
       "2        1    0  122    0    1    0    1    1    2    1   129\n",
       "3        0    1    3  136    1    2    1    2    2    2   150\n",
       "4        1    0    0    0  141    0    1    1    1    6   151\n",
       "5        0    0    1    5    0  150    6    0    1    0   163\n",
       "6        1    0    1    0    1    2  141    0    0    0   146\n",
       "7        0    0    2    0    1    0    0  143    0    1   147\n",
       "8        0    0    2    6    1    4    2    0  151    0   166\n",
       "9        3    0    0    1    2    1    0    0    1  140   148\n",
       "All    148  151  135  150  148  160  152  148  158  150  1500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y = sess.run(tf.argmax(h,1), feed_dict={x:test_x})\n",
    "cross_tab= pd.crosstab(test_y.argmax(axis=1),predict_y,margins= True)\n",
    "cross_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN을 이용한 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T02:54:18.113723Z",
     "start_time": "2020-07-08T02:54:18.095722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2000)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "img = cv2.imread(\"digits.png\", cv2.IMREAD_GRAYSCALE)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T02:54:21.405911Z",
     "start_time": "2020-07-08T02:54:21.368909Z"
    }
   },
   "outputs": [],
   "source": [
    "cells = [np.hsplit(row , 100) for row in np.vsplit(img,50)]\n",
    "x = np.array(cells) / 255. # 0과 1사이에 하기 위해서 255를 난눠줌. cells 는 0과 255사이에 있기 때문에\n",
    "X = x[:,:].reshape(-1,400).astype(np.float32)\n",
    "y= pd.get_dummies(np.repeat(np.arange(10),500)).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 레이어 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T05:13:45.796689Z",
     "start_time": "2020-07-08T05:13:45.773688Z"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 400])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "x_image = tf.reshape(x, [-1,20,20,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T05:18:55.185923Z",
     "start_time": "2020-07-08T05:18:55.145921Z"
    }
   },
   "outputs": [],
   "source": [
    "w_conv1 = tf.Variable(tf.truncated_normal([3,3,1,32], stddev= 0.1))\n",
    "# b_conv1  = tf.constant(0.1,shape=[32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, w_conv1, strides = [1,1,1,1] , padding='SAME'))\n",
    "h_pool1 = tf.nn.max_pool(h_conv1, ksize = [1,2,2,1], strides = [1,2,2,1] , padding='SAME')\n",
    "h_pool1_drop = tf.nn.dropout(h_pool1, rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T05:35:35.506913Z",
     "start_time": "2020-07-08T05:35:35.463911Z"
    }
   },
   "outputs": [],
   "source": [
    "w_conv2 = tf.Variable(tf.truncated_normal([3,3,32,64], stddev= 0.1))\n",
    "# b_conv1  = tf.constant(0.1,shape=[32])\n",
    "\n",
    "h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1_drop, w_conv2, strides = [1,1,1,1] , padding='SAME'))\n",
    "h_pool2 = tf.nn.max_pool(h_conv2, ksize = [1,2,2,1], strides = [1,2,2,1] , padding='SAME')\n",
    "h_pool2_drop = tf.nn.dropout(h_pool2, rate=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T05:36:19.190610Z",
     "start_time": "2020-07-08T05:36:18.639578Z"
    }
   },
   "outputs": [],
   "source": [
    "W_fc1 = tf.Variable(tf.truncated_normal([5*5*64, 1024], stddev=0.1)) # 5*5는 이미지 크기에 따라 바뀐다.\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1,5*5*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1))\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, rate=0.5)\n",
    "\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([1024,10], stddev=0.1))\n",
    "h = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2))\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y * tf.log(h), reduction_indices=[1])\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "train = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "tot_cnt = len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T05:36:51.940483Z",
     "start_time": "2020-07-08T05:36:28.784159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "026 - 0.004987\r"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    avg_loss = 0\n",
    "    batch_size = 128\n",
    "    tot_iter = int(tot_cnt / batch_size)\n",
    "    for step in range(tot_iter):\n",
    "        batch_x = train_x[int(step*batch_size):int((step+1)*batch_size)]\n",
    "        batch_y = train_y[int(step*batch_size):int((step+1)*batch_size)]\n",
    "        _, loss_ = sess.run([train, loss], feed_dict={x:batch_x, y:batch_y})\n",
    "        avg_loss += (loss_ / tot_iter)\n",
    "        print(\"{:03d} - {:f}\".format(step, loss_), end=\"\\r\")\n",
    "    if len(train_x)//tot_iter != 0:\n",
    "        batch_x = train_x[int(tot_iter*batch_size):]\n",
    "        batch_y = train_y[int(tot_iter*batch_size):]\n",
    "        print(\"{:03d} - {:f}\".format(step, loss_), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T05:37:01.759428Z",
     "start_time": "2020-07-08T05:37:01.544416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(h, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x:test_x, y:test_y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 케라스를 이용한 분류 (CNN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  입력데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:09:12.231101Z",
     "start_time": "2020-07-09T03:09:12.173900Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "img = cv2.imread(\"digits.png\", cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:09:18.568191Z",
     "start_time": "2020-07-09T03:09:18.549591Z"
    }
   },
   "outputs": [],
   "source": [
    "cells = [np.hsplit(row,100) for row in np.vsplit(img,50)]\n",
    "x = np.array(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:09:24.961655Z",
     "start_time": "2020-07-09T03:09:24.939055Z"
    }
   },
   "outputs": [],
   "source": [
    "cells = [np.hsplit(row,100) for row in np.vsplit(img,50)]\n",
    "x = np.array(cells) \n",
    "img_rows, img_cols = 20,20\n",
    "x = x.reshape(-1, img_rows,img_cols, 1)\n",
    "y = pd.get_dummies(np.repeat(np.arange(10),500)).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:09:31.378905Z",
     "start_time": "2020-07-09T03:09:31.363305Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y , test_y = train_test_split(x,y,test_size=0.3 , \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 파일에 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:09:39.749564Z",
     "start_time": "2020-07-09T03:09:37.802853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.0%[                                                  ] 0\r",
      "  0.0%[                                                  ] 1\r",
      "  0.0%[                                                  ] 2\r",
      "  0.1%[                                                  ] 3\r",
      "  0.1%[                                                  ] 4\r",
      "  0.1%[                                                  ] 5\r",
      "  0.1%[                                                  ] 6\r",
      "  0.1%[                                                  ] 7\r",
      "  0.2%[                                                  ] 8\r",
      "  0.2%[                                                  ] 9\r",
      "  0.2%[                                                  ] 10\r",
      "  0.2%[                                                  ] 11\r",
      "  0.2%[                                                  ] 12\r",
      "  0.3%[                                                  ] 13\r",
      "  0.3%[                                                  ] 14\r",
      "  0.3%[                                                  ] 15\r",
      "  0.3%[                                                  ] 16\r",
      "  0.3%[                                                  ] 17\r",
      "  0.4%[                                                  ] 18\r",
      "  0.4%[                                                  ] 19\r",
      "  0.4%[                                                  ] 20\r",
      "  0.4%[                                                  ] 21\r",
      "  0.4%[                                                  ] 22\r",
      "  0.5%[                                                  ] 23\r",
      "  0.5%[                                                  ] 24\r",
      "  0.5%[                                                  ] 25\r",
      "  0.5%[                                                  ] 26\r",
      "  0.5%[                                                  ] 27\r",
      "  0.6%[                                                  ] 28\r",
      "  0.6%[                                                  ] 29\r",
      "  0.6%[                                                  ] 30\r",
      "  0.6%[                                                  ] 31\r",
      "  0.6%[                                                  ] 32\r",
      "  0.7%[                                                  ] 33\r",
      "  0.7%[                                                  ] 34\r",
      "  0.7%[                                                  ] 35\r",
      "  0.7%[                                                  ] 36\r",
      "  0.7%[                                                  ] 37\r",
      "  0.8%[                                                  ] 38\r",
      "  0.8%[                                                  ] 39\r",
      "  0.8%[                                                  ] 40\r",
      "  0.8%[                                                  ] 41\r",
      "  0.8%[                                                  ] 42\r",
      "  0.9%[                                                  ] 43\r",
      "  0.9%[                                                  ] 44\r",
      "  0.9%[                                                  ] 45\r",
      "  0.9%[                                                  ] 46\r",
      "  0.9%[                                                  ] 47\r",
      "  1.0%[                                                  ] 48\r",
      "  1.0%[                                                  ] 49\r",
      "  1.0%[                                                  ] 50\r",
      "  1.0%[                                                  ] 51\r",
      "  1.0%[                                                  ] 52\r",
      "  1.1%[                                                  ] 53\r",
      "  1.1%[                                                  ] 54\r",
      "  1.1%[                                                  ] 55\r",
      "  1.1%[                                                  ] 56\r",
      "  1.1%[                                                  ] 57\r",
      "  1.2%[                                                  ] 58\r",
      "  1.2%[                                                  ] 59\r",
      "  1.2%[                                                  ] 60\r",
      "  1.2%[                                                  ] 61\r",
      "  1.2%[                                                  ] 62\r",
      "  1.3%[                                                  ] 63\r",
      "  1.3%[                                                  ] 64\r",
      "  1.3%[                                                  ] 65\r",
      "  1.3%[                                                  ] 66\r",
      "  1.3%[                                                  ] 67\r",
      "  1.4%[                                                  ] 68\r",
      "  1.4%[                                                  ] 69\r",
      "  1.4%[                                                  ] 70\r",
      "  1.4%[                                                  ] 71\r",
      "  1.4%[                                                  ] 72\r",
      "  1.5%[                                                  ] 73\r",
      "  1.5%[                                                  ] 74\r",
      "  1.5%[                                                  ] 75\r",
      "  1.5%[                                                  ] 76\r",
      "  1.5%[                                                  ] 77\r",
      "  1.6%[                                                  ] 78\r",
      "  1.6%[                                                  ] 79\r",
      "  1.6%[                                                  ] 80\r",
      "  1.6%[                                                  ] 81\r",
      "  1.6%[                                                  ] 82\r",
      "  1.7%[                                                  ] 83\r",
      "  1.7%[                                                  ] 84\r",
      "  1.7%[                                                  ] 85\r",
      "  1.7%[                                                  ] 86\r",
      "  1.7%[                                                  ] 87\r",
      "  1.8%[                                                  ] 88\r",
      "  1.8%[                                                  ] 89\r",
      "  1.8%[                                                  ] 90\r",
      "  1.8%[                                                  ] 91\r",
      "  1.8%[                                                  ] 92\r",
      "  1.9%[                                                  ] 93\r",
      "  1.9%[                                                  ] 94\r",
      "  1.9%[                                                  ] 95\r",
      "  1.9%[                                                  ] 96\r",
      "  1.9%[                                                  ] 97\r",
      "  2.0%[                                                  ] 98\r",
      "  2.0%[                                                  ] 99\r",
      "  2.0%[#                                                 ] 100\r",
      "  2.0%[#                                                 ] 101\r",
      "  2.0%[#                                                 ] 102\r",
      "  2.1%[#                                                 ] 103\r",
      "  2.1%[#                                                 ] 104\r",
      "  2.1%[#                                                 ] 105\r",
      "  2.1%[#                                                 ] 106\r",
      "  2.1%[#                                                 ] 107\r",
      "  2.2%[#                                                 ] 108\r",
      "  2.2%[#                                                 ] 109\r",
      "  2.2%[#                                                 ] 110\r",
      "  2.2%[#                                                 ] 111\r",
      "  2.2%[#                                                 ] 112\r",
      "  2.3%[#                                                 ] 113\r",
      "  2.3%[#                                                 ] 114\r",
      "  2.3%[#                                                 ] 115\r",
      "  2.3%[#                                                 ] 116\r",
      "  2.3%[#                                                 ] 117\r",
      "  2.4%[#                                                 ] 118\r",
      "  2.4%[#                                                 ] 119\r",
      "  2.4%[#                                                 ] 120\r",
      "  2.4%[#                                                 ] 121\r",
      "  2.4%[#                                                 ] 122\r",
      "  2.5%[#                                                 ] 123\r",
      "  2.5%[#                                                 ] 124\r",
      "  2.5%[#                                                 ] 125\r",
      "  2.5%[#                                                 ] 126\r",
      "  2.5%[#                                                 ] 127\r",
      "  2.6%[#                                                 ] 128\r",
      "  2.6%[#                                                 ] 129\r",
      "  2.6%[#                                                 ] 130\r",
      "  2.6%[#                                                 ] 131\r",
      "  2.6%[#                                                 ] 132\r",
      "  2.7%[#                                                 ] 133\r",
      "  2.7%[#                                                 ] 134\r",
      "  2.7%[#                                                 ] 135\r",
      "  2.7%[#                                                 ] 136\r",
      "  2.7%[#                                                 ] 137\r",
      "  2.8%[#                                                 ] 138\r",
      "  2.8%[#                                                 ] 139\r",
      "  2.8%[#                                                 ] 140\r",
      "  2.8%[#                                                 ] 141\r",
      "  2.8%[#                                                 ] 142\r",
      "  2.9%[#                                                 ] 143\r",
      "  2.9%[#                                                 ] 144\r",
      "  2.9%[#                                                 ] 145\r",
      "  2.9%[#                                                 ] 146\r",
      "  2.9%[#                                                 ] 147\r",
      "  3.0%[#                                                 ] 148\r",
      "  3.0%[#                                                 ] 149\r",
      "  3.0%[#                                                 ] 150\r",
      "  3.0%[#                                                 ] 151\r",
      "  3.0%[#                                                 ] 152\r",
      "  3.1%[#                                                 ] 153\r",
      "  3.1%[#                                                 ] 154\r",
      "  3.1%[#                                                 ] 155\r",
      "  3.1%[#                                                 ] 156\r",
      "  3.1%[#                                                 ] 157\r",
      "  3.2%[#                                                 ] 158\r",
      "  3.2%[#                                                 ] 159\r",
      "  3.2%[#                                                 ] 160\r",
      "  3.2%[#                                                 ] 161\r",
      "  3.2%[#                                                 ] 162\r",
      "  3.3%[#                                                 ] 163\r",
      "  3.3%[#                                                 ] 164\r",
      "  3.3%[#                                                 ] 165\r",
      "  3.3%[#                                                 ] 166\r",
      "  3.3%[#                                                 ] 167\r",
      "  3.4%[#                                                 ] 168\r",
      "  3.4%[#                                                 ] 169\r",
      "  3.4%[#                                                 ] 170\r",
      "  3.4%[#                                                 ] 171\r",
      "  3.4%[#                                                 ] 172\r",
      "  3.5%[#                                                 ] 173\r",
      "  3.5%[#                                                 ] 174\r",
      "  3.5%[#                                                 ] 175\r",
      "  3.5%[#                                                 ] 176\r",
      "  3.5%[#                                                 ] 177\r",
      "  3.6%[#                                                 ] 178\r",
      "  3.6%[#                                                 ] 179\r",
      "  3.6%[#                                                 ] 180\r",
      "  3.6%[#                                                 ] 181\r",
      "  3.6%[#                                                 ] 182\r",
      "  3.7%[#                                                 ] 183\r",
      "  3.7%[#                                                 ] 184\r",
      "  3.7%[#                                                 ] 185\r",
      "  3.7%[#                                                 ] 186\r",
      "  3.7%[#                                                 ] 187\r",
      "  3.8%[#                                                 ] 188\r",
      "  3.8%[#                                                 ] 189\r",
      "  3.8%[#                                                 ] 190\r",
      "  3.8%[#                                                 ] 191\r",
      "  3.8%[#                                                 ] 192\r",
      "  3.9%[#                                                 ] 193\r",
      "  3.9%[#                                                 ] 194\r",
      "  3.9%[#                                                 ] 195\r",
      "  3.9%[#                                                 ] 196\r",
      "  3.9%[#                                                 ] 197\r",
      "  4.0%[#                                                 ] 198\r",
      "  4.0%[#                                                 ] 199\r",
      "  4.0%[##                                                ] 200\r",
      "  4.0%[##                                                ] 201\r",
      "  4.0%[##                                                ] 202\r",
      "  4.1%[##                                                ] 203\r",
      "  4.1%[##                                                ] 204\r",
      "  4.1%[##                                                ] 205\r",
      "  4.1%[##                                                ] 206\r",
      "  4.1%[##                                                ] 207\r",
      "  4.2%[##                                                ] 208\r",
      "  4.2%[##                                                ] 209\r",
      "  4.2%[##                                                ] 210\r",
      "  4.2%[##                                                ] 211\r",
      "  4.2%[##                                                ] 212\r",
      "  4.3%[##                                                ] 213\r",
      "  4.3%[##                                                ] 214\r",
      "  4.3%[##                                                ] 215\r",
      "  4.3%[##                                                ] 216\r",
      "  4.3%[##                                                ] 217\r",
      "  4.4%[##                                                ] 218\r",
      "  4.4%[##                                                ] 219\r",
      "  4.4%[##                                                ] 220\r",
      "  4.4%[##                                                ] 221\r",
      "  4.4%[##                                                ] 222\r",
      "  4.5%[##                                                ] 223\r",
      "  4.5%[##                                                ] 224\r",
      "  4.5%[##                                                ] 225\r",
      "  4.5%[##                                                ] 226\r",
      "  4.5%[##                                                ] 227\r",
      "  4.6%[##                                                ] 228\r",
      "  4.6%[##                                                ] 229\r",
      "  4.6%[##                                                ] 230\r",
      "  4.6%[##                                                ] 231\r",
      "  4.6%[##                                                ] 232\r",
      "  4.7%[##                                                ] 233\r",
      "  4.7%[##                                                ] 234\r",
      "  4.7%[##                                                ] 235\r",
      "  4.7%[##                                                ] 236\r",
      "  4.7%[##                                                ] 237\r",
      "  4.8%[##                                                ] 238\r",
      "  4.8%[##                                                ] 239\r",
      "  4.8%[##                                                ] 240\r",
      "  4.8%[##                                                ] 241\r",
      "  4.8%[##                                                ] 242\r",
      "  4.9%[##                                                ] 243\r",
      "  4.9%[##                                                ] 244\r",
      "  4.9%[##                                                ] 245\r",
      "  4.9%[##                                                ] 246\r",
      "  4.9%[##                                                ] 247\r",
      "  5.0%[##                                                ] 248\r",
      "  5.0%[##                                                ] 249\r",
      "  5.0%[##                                                ] 250\r",
      "  5.0%[##                                                ] 251\r",
      "  5.0%[##                                                ] 252\r",
      "  5.1%[##                                                ] 253\r",
      "  5.1%[##                                                ] 254\r",
      "  5.1%[##                                                ] 255\r",
      "  5.1%[##                                                ] 256\r",
      "  5.1%[##                                                ] 257\r",
      "  5.2%[##                                                ] 258\r",
      "  5.2%[##                                                ] 259\r",
      "  5.2%[##                                                ] 260\r",
      "  5.2%[##                                                ] 261\r",
      "  5.2%[##                                                ] 262\r",
      "  5.3%[##                                                ] 263\r",
      "  5.3%[##                                                ] 264\r",
      "  5.3%[##                                                ] 265\r",
      "  5.3%[##                                                ] 266\r",
      "  5.3%[##                                                ] 267\r",
      "  5.4%[##                                                ] 268\r",
      "  5.4%[##                                                ] 269\r",
      "  5.4%[##                                                ] 270\r",
      "  5.4%[##                                                ] 271\r",
      "  5.4%[##                                                ] 272\r",
      "  5.5%[##                                                ] 273\r",
      "  5.5%[##                                                ] 274\r",
      "  5.5%[##                                                ] 275\r",
      "  5.5%[##                                                ] 276\r",
      "  5.5%[##                                                ] 277\r",
      "  5.6%[##                                                ] 278\r",
      "  5.6%[##                                                ] 279\r",
      "  5.6%[##                                                ] 280\r",
      "  5.6%[##                                                ] 281\r",
      "  5.6%[##                                                ] 282\r",
      "  5.7%[##                                                ] 283\r",
      "  5.7%[##                                                ] 284\r",
      "  5.7%[##                                                ] 285\r",
      "  5.7%[##                                                ] 286\r",
      "  5.7%[##                                                ] 287\r",
      "  5.8%[##                                                ] 288\r",
      "  5.8%[##                                                ] 289\r",
      "  5.8%[##                                                ] 290\r",
      "  5.8%[##                                                ] 291\r",
      "  5.8%[##                                                ] 292\r",
      "  5.9%[##                                                ] 293\r",
      "  5.9%[##                                                ] 294\r",
      "  5.9%[##                                                ] 295\r",
      "  5.9%[##                                                ] 296\r",
      "  5.9%[##                                                ] 297\r",
      "  6.0%[##                                                ] 298\r",
      "  6.0%[##                                                ] 299\r",
      "  6.0%[###                                               ] 300\r",
      "  6.0%[###                                               ] 301\r",
      "  6.0%[###                                               ] 302\r",
      "  6.1%[###                                               ] 303\r",
      "  6.1%[###                                               ] 304\r",
      "  6.1%[###                                               ] 305\r",
      "  6.1%[###                                               ] 306\r",
      "  6.1%[###                                               ] 307\r",
      "  6.2%[###                                               ] 308\r",
      "  6.2%[###                                               ] 309\r",
      "  6.2%[###                                               ] 310\r",
      "  6.2%[###                                               ] 311\r",
      "  6.2%[###                                               ] 312\r",
      "  6.3%[###                                               ] 313\r",
      "  6.3%[###                                               ] 314\r",
      "  6.3%[###                                               ] 315\r",
      "  6.3%[###                                               ] 316\r",
      "  6.3%[###                                               ] 317\r",
      "  6.4%[###                                               ] 318\r",
      "  6.4%[###                                               ] 319\r",
      "  6.4%[###                                               ] 320\r",
      "  6.4%[###                                               ] 321\r",
      "  6.4%[###                                               ] 322\r",
      "  6.5%[###                                               ] 323\r",
      "  6.5%[###                                               ] 324\r",
      "  6.5%[###                                               ] 325\r",
      "  6.5%[###                                               ] 326\r",
      "  6.5%[###                                               ] 327\r",
      "  6.6%[###                                               ] 328\r",
      "  6.6%[###                                               ] 329\r",
      "  6.6%[###                                               ] 330\r",
      "  6.6%[###                                               ] 331\r",
      "  6.6%[###                                               ] 332\r",
      "  6.7%[###                                               ] 333\r",
      "  6.7%[###                                               ] 334\r",
      "  6.7%[###                                               ] 335\r",
      "  6.7%[###                                               ] 336\r",
      "  6.7%[###                                               ] 337\r",
      "  6.8%[###                                               ] 338\r",
      "  6.8%[###                                               ] 339\r",
      "  6.8%[###                                               ] 340\r",
      "  6.8%[###                                               ] 341\r",
      "  6.8%[###                                               ] 342\r",
      "  6.9%[###                                               ] 343\r",
      "  6.9%[###                                               ] 344\r",
      "  6.9%[###                                               ] 345\r",
      "  6.9%[###                                               ] 346\r",
      "  6.9%[###                                               ] 347\r",
      "  7.0%[###                                               ] 348\r",
      "  7.0%[###                                               ] 349\r",
      "  7.0%[###                                               ] 350\r",
      "  7.0%[###                                               ] 351\r",
      "  7.0%[###                                               ] 352\r",
      "  7.1%[###                                               ] 353\r",
      "  7.1%[###                                               ] 354\r",
      "  7.1%[###                                               ] 355\r",
      "  7.1%[###                                               ] 356\r",
      "  7.1%[###                                               ] 357\r",
      "  7.2%[###                                               ] 358\r",
      "  7.2%[###                                               ] 359\r",
      "  7.2%[###                                               ] 360\r",
      "  7.2%[###                                               ] 361\r",
      "  7.2%[###                                               ] 362\r",
      "  7.3%[###                                               ] 363\r",
      "  7.3%[###                                               ] 364\r",
      "  7.3%[###                                               ] 365\r",
      "  7.3%[###                                               ] 366\r",
      "  7.3%[###                                               ] 367\r",
      "  7.4%[###                                               ] 368\r",
      "  7.4%[###                                               ] 369\r",
      "  7.4%[###                                               ] 370\r",
      "  7.4%[###                                               ] 371"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%[################################################# ] 4999\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"digits\"\n",
    "for i, img_data in enumerate(x):\n",
    "    number_dir = str(y[i])\n",
    "    img_name = '%04d.jpg'%i\n",
    "    img_dir = os.path.join(path, number_dir)\n",
    "    img_path = os.path.join(path, number_dir, img_name)\n",
    "    os.makedirs(img_dir, exist_ok=True)\n",
    "    cv2.imwrite(img_path, img_data)\n",
    "    # 아래 코드는 진행상황을 보기 위함\n",
    "    percent = (i/5000) * 100 # 숫자 5000개\n",
    "    progress = int(percent*5/10) * '#'\n",
    "    print(\"{:5.1f}%[{:<50s}] {}\".format(percent, progress, i), end= \"\\r\")\n",
    "    # if i>2:\n",
    "#         break:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 레이어 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:09:46.235615Z",
     "start_time": "2020-07-09T03:09:46.115410Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential()\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "model.add(Conv2D(32, kernel_size = (3,3),\n",
    "                input_shape= (img_rows, img_cols , 1 ), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3,3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "          \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:09:52.612073Z",
     "start_time": "2020-07-09T03:09:52.596473Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(filepath = \"digits-{epoch:03d}-{val_acc:.4f}.hdf5\",\n",
    "                            monitor=\"val_acc\", save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:09:59.118794Z",
     "start_time": "2020-07-09T03:09:59.103194Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_acc\", patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:10:05.871489Z",
     "start_time": "2020-07-09T03:10:05.809288Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model.compile(loss= tf.keras.losses.categorical_crossentropy,\n",
    "             optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "             metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:10:47.510622Z",
     "start_time": "2020-07-09T03:10:12.354583Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3500 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 17.3215 - acc: 0.2127\n",
      "Epoch 00001: val_acc improved from -inf to 0.33600, saving model to digits-001-0.3360.hdf5\n",
      "3500/3500 [==============================] - 1s 282us/sample - loss: 17.1374 - acc: 0.2146 - val_loss: 1.9468 - val_acc: 0.3360\n",
      "Epoch 2/50\n",
      "3328/3500 [===========================>..] - ETA: 0s - loss: 2.1773 - acc: 0.2437\n",
      "Epoch 00002: val_acc improved from 0.33600 to 0.37533, saving model to digits-002-0.3753.hdf5\n",
      "3500/3500 [==============================] - 1s 200us/sample - loss: 2.1688 - acc: 0.2460 - val_loss: 1.8831 - val_acc: 0.3753\n",
      "Epoch 3/50\n",
      "3200/3500 [==========================>...] - ETA: 0s - loss: 1.9742 - acc: 0.2859\n",
      "Epoch 00003: val_acc improved from 0.37533 to 0.55667, saving model to digits-003-0.5567.hdf5\n",
      "3500/3500 [==============================] - 1s 205us/sample - loss: 1.9695 - acc: 0.2931 - val_loss: 1.5304 - val_acc: 0.5567\n",
      "Epoch 4/50\n",
      "3328/3500 [===========================>..] - ETA: 0s - loss: 1.7787 - acc: 0.4053\n",
      "Epoch 00004: val_acc improved from 0.55667 to 0.68333, saving model to digits-004-0.6833.hdf5\n",
      "3500/3500 [==============================] - 1s 200us/sample - loss: 1.7679 - acc: 0.4094 - val_loss: 1.1832 - val_acc: 0.6833\n",
      "Epoch 5/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 1.6133 - acc: 0.4745\n",
      "Epoch 00005: val_acc improved from 0.68333 to 0.70133, saving model to digits-005-0.7013.hdf5\n",
      "3500/3500 [==============================] - 1s 201us/sample - loss: 1.6104 - acc: 0.4749 - val_loss: 1.0711 - val_acc: 0.7013\n",
      "Epoch 6/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 1.4482 - acc: 0.5422\n",
      "Epoch 00006: val_acc improved from 0.70133 to 0.80000, saving model to digits-006-0.8000.hdf5\n",
      "3500/3500 [==============================] - 1s 200us/sample - loss: 1.4452 - acc: 0.5431 - val_loss: 0.8289 - val_acc: 0.8000\n",
      "Epoch 7/50\n",
      "3328/3500 [===========================>..] - ETA: 0s - loss: 1.2635 - acc: 0.5904\n",
      "Epoch 00007: val_acc improved from 0.80000 to 0.82000, saving model to digits-007-0.8200.hdf5\n",
      "3500/3500 [==============================] - 1s 195us/sample - loss: 1.2655 - acc: 0.5923 - val_loss: 0.6893 - val_acc: 0.8200\n",
      "Epoch 8/50\n",
      "3200/3500 [==========================>...] - ETA: 0s - loss: 1.1171 - acc: 0.6425\n",
      "Epoch 00008: val_acc improved from 0.82000 to 0.86133, saving model to digits-008-0.8613.hdf5\n",
      "3500/3500 [==============================] - 1s 200us/sample - loss: 1.1203 - acc: 0.6443 - val_loss: 0.5190 - val_acc: 0.8613\n",
      "Epoch 9/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.9930 - acc: 0.6861\n",
      "Epoch 00009: val_acc improved from 0.86133 to 0.87067, saving model to digits-009-0.8707.hdf5\n",
      "3500/3500 [==============================] - 1s 201us/sample - loss: 0.9952 - acc: 0.6871 - val_loss: 0.4614 - val_acc: 0.8707\n",
      "Epoch 10/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.9066 - acc: 0.7135\n",
      "Epoch 00010: val_acc improved from 0.87067 to 0.89067, saving model to digits-010-0.8907.hdf5\n",
      "3500/3500 [==============================] - 1s 207us/sample - loss: 0.9067 - acc: 0.7140 - val_loss: 0.4138 - val_acc: 0.8907\n",
      "Epoch 11/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.8032 - acc: 0.7488\n",
      "Epoch 00011: val_acc improved from 0.89067 to 0.90333, saving model to digits-011-0.9033.hdf5\n",
      "3500/3500 [==============================] - 1s 226us/sample - loss: 0.7999 - acc: 0.7497 - val_loss: 0.3527 - val_acc: 0.9033\n",
      "Epoch 12/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.7476 - acc: 0.7671\n",
      "Epoch 00012: val_acc improved from 0.90333 to 0.91200, saving model to digits-012-0.9120.hdf5\n",
      "3500/3500 [==============================] - 1s 224us/sample - loss: 0.7473 - acc: 0.7657 - val_loss: 0.3100 - val_acc: 0.9120\n",
      "Epoch 13/50\n",
      "3328/3500 [===========================>..] - ETA: 0s - loss: 0.6770 - acc: 0.7975\n",
      "Epoch 00013: val_acc improved from 0.91200 to 0.92200, saving model to digits-013-0.9220.hdf5\n",
      "3500/3500 [==============================] - 1s 205us/sample - loss: 0.6720 - acc: 0.8006 - val_loss: 0.2917 - val_acc: 0.9220\n",
      "Epoch 14/50\n",
      "3328/3500 [===========================>..] - ETA: 0s - loss: 0.6484 - acc: 0.8095\n",
      "Epoch 00014: val_acc improved from 0.92200 to 0.92533, saving model to digits-014-0.9253.hdf5\n",
      "3500/3500 [==============================] - 1s 210us/sample - loss: 0.6473 - acc: 0.8094 - val_loss: 0.2803 - val_acc: 0.9253\n",
      "Epoch 15/50\n",
      "3328/3500 [===========================>..] - ETA: 0s - loss: 0.5487 - acc: 0.8338\n",
      "Epoch 00015: val_acc did not improve from 0.92533\n",
      "3500/3500 [==============================] - 1s 215us/sample - loss: 0.5482 - acc: 0.8334 - val_loss: 0.2657 - val_acc: 0.9220\n",
      "Epoch 16/50\n",
      "3328/3500 [===========================>..] - ETA: 0s - loss: 0.5344 - acc: 0.8323\n",
      "Epoch 00016: val_acc improved from 0.92533 to 0.93200, saving model to digits-016-0.9320.hdf5\n",
      "3500/3500 [==============================] - 1s 200us/sample - loss: 0.5412 - acc: 0.8306 - val_loss: 0.2391 - val_acc: 0.9320\n",
      "Epoch 17/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.4733 - acc: 0.8501\n",
      "Epoch 00017: val_acc did not improve from 0.93200\n",
      "3500/3500 [==============================] - 1s 205us/sample - loss: 0.4721 - acc: 0.8509 - val_loss: 0.2451 - val_acc: 0.9313\n",
      "Epoch 18/50\n",
      "3200/3500 [==========================>...] - ETA: 0s - loss: 0.4492 - acc: 0.8616\n",
      "Epoch 00018: val_acc did not improve from 0.93200\n",
      "3500/3500 [==============================] - 1s 195us/sample - loss: 0.4461 - acc: 0.8631 - val_loss: 0.2219 - val_acc: 0.9293\n",
      "Epoch 19/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.4094 - acc: 0.8669\n",
      "Epoch 00019: val_acc improved from 0.93200 to 0.94333, saving model to digits-019-0.9433.hdf5\n",
      "3500/3500 [==============================] - 1s 200us/sample - loss: 0.4150 - acc: 0.8663 - val_loss: 0.1923 - val_acc: 0.9433\n",
      "Epoch 20/50\n",
      "3328/3500 [===========================>..] - ETA: 0s - loss: 0.4013 - acc: 0.8744\n",
      "Epoch 00020: val_acc did not improve from 0.94333\n",
      "3500/3500 [==============================] - 1s 199us/sample - loss: 0.4000 - acc: 0.8760 - val_loss: 0.1890 - val_acc: 0.9427\n",
      "Epoch 21/50\n",
      "3200/3500 [==========================>...] - ETA: 0s - loss: 0.3964 - acc: 0.8884\n",
      "Epoch 00021: val_acc did not improve from 0.94333\n",
      "3500/3500 [==============================] - 1s 200us/sample - loss: 0.3973 - acc: 0.8869 - val_loss: 0.1931 - val_acc: 0.9367\n",
      "Epoch 22/50\n",
      "3200/3500 [==========================>...] - ETA: 0s - loss: 0.3866 - acc: 0.8819\n",
      "Epoch 00022: val_acc improved from 0.94333 to 0.94800, saving model to digits-022-0.9480.hdf5\n",
      "3500/3500 [==============================] - 1s 200us/sample - loss: 0.3776 - acc: 0.8843 - val_loss: 0.1677 - val_acc: 0.9480\n",
      "Epoch 23/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.3747 - acc: 0.8857\n",
      "Epoch 00023: val_acc did not improve from 0.94800\n",
      "3500/3500 [==============================] - 1s 201us/sample - loss: 0.3761 - acc: 0.8857 - val_loss: 0.1708 - val_acc: 0.9467\n",
      "Epoch 24/50\n",
      "3200/3500 [==========================>...] - ETA: 0s - loss: 0.3310 - acc: 0.8981\n",
      "Epoch 00024: val_acc improved from 0.94800 to 0.95333, saving model to digits-024-0.9533.hdf5\n",
      "3500/3500 [==============================] - 1s 199us/sample - loss: 0.3338 - acc: 0.8994 - val_loss: 0.1669 - val_acc: 0.9533\n",
      "Epoch 25/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.3165 - acc: 0.9045\n",
      "Epoch 00025: val_acc did not improve from 0.95333\n",
      "3500/3500 [==============================] - 1s 212us/sample - loss: 0.3153 - acc: 0.9049 - val_loss: 0.1609 - val_acc: 0.9473\n",
      "Epoch 26/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.2890 - acc: 0.9091\n",
      "Epoch 00026: val_acc did not improve from 0.95333\n",
      "3500/3500 [==============================] - 1s 209us/sample - loss: 0.2934 - acc: 0.9083 - val_loss: 0.1718 - val_acc: 0.9487\n",
      "Epoch 27/50\n",
      "3200/3500 [==========================>...] - ETA: 0s - loss: 0.2877 - acc: 0.9131\n",
      "Epoch 00027: val_acc did not improve from 0.95333\n",
      "3500/3500 [==============================] - 1s 194us/sample - loss: 0.2855 - acc: 0.9131 - val_loss: 0.1473 - val_acc: 0.9520\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3328/3500 [===========================>..] - ETA: 0s - loss: 0.2883 - acc: 0.9123\n",
      "Epoch 00028: val_acc did not improve from 0.95333\n",
      "3500/3500 [==============================] - 1s 192us/sample - loss: 0.2895 - acc: 0.9117 - val_loss: 0.1502 - val_acc: 0.9513\n",
      "Epoch 29/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.2734 - acc: 0.9164- ETA: 0s - loss: 0.2638 - acc: 0\n",
      "Epoch 00029: val_acc improved from 0.95333 to 0.95400, saving model to digits-029-0.9540.hdf5\n",
      "3500/3500 [==============================] - 1s 200us/sample - loss: 0.2727 - acc: 0.9163 - val_loss: 0.1610 - val_acc: 0.9540\n",
      "Epoch 30/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.2428 - acc: 0.9207\n",
      "Epoch 00030: val_acc did not improve from 0.95400\n",
      "3500/3500 [==============================] - 1s 191us/sample - loss: 0.2419 - acc: 0.9214 - val_loss: 0.1509 - val_acc: 0.9487\n",
      "Epoch 31/50\n",
      "3200/3500 [==========================>...] - ETA: 0s - loss: 0.2348 - acc: 0.9272\n",
      "Epoch 00031: val_acc did not improve from 0.95400\n",
      "3500/3500 [==============================] - 1s 195us/sample - loss: 0.2387 - acc: 0.9266 - val_loss: 0.1573 - val_acc: 0.9527\n",
      "Epoch 32/50\n",
      "3200/3500 [==========================>...] - ETA: 0s - loss: 0.2616 - acc: 0.9194\n",
      "Epoch 00032: val_acc improved from 0.95400 to 0.95467, saving model to digits-032-0.9547.hdf5\n",
      "3500/3500 [==============================] - 1s 199us/sample - loss: 0.2546 - acc: 0.9203 - val_loss: 0.1380 - val_acc: 0.9547\n",
      "Epoch 33/50\n",
      "3200/3500 [==========================>...] - ETA: 0s - loss: 0.2249 - acc: 0.9287\n",
      "Epoch 00033: val_acc did not improve from 0.95467\n",
      "3500/3500 [==============================] - 1s 196us/sample - loss: 0.2249 - acc: 0.9277 - val_loss: 0.1293 - val_acc: 0.9507\n",
      "Epoch 34/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.2292 - acc: 0.9340\n",
      "Epoch 00034: val_acc improved from 0.95467 to 0.95933, saving model to digits-034-0.9593.hdf5\n",
      "3500/3500 [==============================] - 1s 201us/sample - loss: 0.2341 - acc: 0.9331 - val_loss: 0.1408 - val_acc: 0.9593\n",
      "Epoch 35/50\n",
      "3328/3500 [===========================>..] - ETA: 0s - loss: 0.2313 - acc: 0.9303\n",
      "Epoch 00035: val_acc did not improve from 0.95933\n",
      "3500/3500 [==============================] - 1s 201us/sample - loss: 0.2304 - acc: 0.9314 - val_loss: 0.1412 - val_acc: 0.9593\n",
      "Epoch 36/50\n",
      "3328/3500 [===========================>..] - ETA: 0s - loss: 0.2068 - acc: 0.9390\n",
      "Epoch 00036: val_acc did not improve from 0.95933\n",
      "3500/3500 [==============================] - 1s 196us/sample - loss: 0.2114 - acc: 0.9389 - val_loss: 0.1507 - val_acc: 0.9580\n",
      "Epoch 37/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.1906 - acc: 0.9424\n",
      "Epoch 00037: val_acc did not improve from 0.95933\n",
      "3500/3500 [==============================] - 1s 191us/sample - loss: 0.1915 - acc: 0.9423 - val_loss: 0.1285 - val_acc: 0.9580\n",
      "Epoch 38/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.1954 - acc: 0.9334\n",
      "Epoch 00038: val_acc did not improve from 0.95933\n",
      "3500/3500 [==============================] - 1s 195us/sample - loss: 0.1964 - acc: 0.9331 - val_loss: 0.1360 - val_acc: 0.9560\n",
      "Epoch 39/50\n",
      "3328/3500 [===========================>..] - ETA: 0s - loss: 0.1940 - acc: 0.9426\n",
      "Epoch 00039: val_acc improved from 0.95933 to 0.96200, saving model to digits-039-0.9620.hdf5\n",
      "3500/3500 [==============================] - 1s 213us/sample - loss: 0.1920 - acc: 0.9423 - val_loss: 0.1374 - val_acc: 0.9620\n",
      "Epoch 40/50\n",
      "3328/3500 [===========================>..] - ETA: 0s - loss: 0.1811 - acc: 0.9432\n",
      "Epoch 00040: val_acc did not improve from 0.96200\n",
      "3500/3500 [==============================] - 1s 189us/sample - loss: 0.1806 - acc: 0.9431 - val_loss: 0.1351 - val_acc: 0.9560\n",
      "Epoch 41/50\n",
      "3328/3500 [===========================>..] - ETA: 0s - loss: 0.1777 - acc: 0.9447\n",
      "Epoch 00041: val_acc improved from 0.96200 to 0.96400, saving model to digits-041-0.9640.hdf5\n",
      "3500/3500 [==============================] - 1s 200us/sample - loss: 0.1818 - acc: 0.9440 - val_loss: 0.1245 - val_acc: 0.9640\n",
      "Epoch 42/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.1631 - acc: 0.9473\n",
      "Epoch 00042: val_acc did not improve from 0.96400\n",
      "3500/3500 [==============================] - 1s 192us/sample - loss: 0.1663 - acc: 0.9466 - val_loss: 0.1331 - val_acc: 0.9627\n",
      "Epoch 43/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.1676 - acc: 0.9537\n",
      "Epoch 00043: val_acc did not improve from 0.96400\n",
      "3500/3500 [==============================] - 1s 191us/sample - loss: 0.1673 - acc: 0.9540 - val_loss: 0.1303 - val_acc: 0.9600\n",
      "Epoch 44/50\n",
      "3200/3500 [==========================>...] - ETA: 0s - loss: 0.1633 - acc: 0.9469\n",
      "Epoch 00044: val_acc improved from 0.96400 to 0.96667, saving model to digits-044-0.9667.hdf5\n",
      "3500/3500 [==============================] - 1s 203us/sample - loss: 0.1608 - acc: 0.9477 - val_loss: 0.1220 - val_acc: 0.9667\n",
      "Epoch 45/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.1802 - acc: 0.9462\n",
      "Epoch 00045: val_acc did not improve from 0.96667\n",
      "3500/3500 [==============================] - 1s 197us/sample - loss: 0.1795 - acc: 0.9463 - val_loss: 0.1387 - val_acc: 0.9567\n",
      "Epoch 46/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.1560 - acc: 0.9476\n",
      "Epoch 00046: val_acc did not improve from 0.96667\n",
      "3500/3500 [==============================] - 1s 195us/sample - loss: 0.1550 - acc: 0.9477 - val_loss: 0.1319 - val_acc: 0.9653\n",
      "Epoch 47/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9592\n",
      "Epoch 00047: val_acc did not improve from 0.96667\n",
      "3500/3500 [==============================] - 1s 195us/sample - loss: 0.1369 - acc: 0.9589 - val_loss: 0.1305 - val_acc: 0.9613\n",
      "Epoch 48/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9552\n",
      "Epoch 00048: val_acc did not improve from 0.96667\n",
      "3500/3500 [==============================] - 1s 196us/sample - loss: 0.1470 - acc: 0.9554 - val_loss: 0.1485 - val_acc: 0.9607\n",
      "Epoch 49/50\n",
      "3456/3500 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9563\n",
      "Epoch 00049: val_acc did not improve from 0.96667\n",
      "3500/3500 [==============================] - 1s 200us/sample - loss: 0.1400 - acc: 0.9554 - val_loss: 0.1260 - val_acc: 0.9660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b2889c8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, validation_data = (test_x, test_y),\n",
    "         callbacks=[checkpoint, early_stopping],\n",
    "         batch_size=128, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:10:54.040098Z",
     "start_time": "2020-07-09T03:10:54.024498Z"
    }
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"digits_model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:11:00.650393Z",
     "start_time": "2020-07-09T03:11:00.543991Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "with open(\"digits_model.json\",\"r\") as json_file:\n",
    "    loaded_model_json =json_file.read()\n",
    "    model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:12:20.637292Z",
     "start_time": "2020-07-09T03:12:20.458885Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"digits-044-0.9667.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:12:27.361094Z",
     "start_time": "2020-07-09T03:12:27.098488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1219771695608894, 0.96666664]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "             optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "             metrics=[\"accuracy\"])\n",
    "model.evaluate(test_x, test_y, verbose =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:12:33.845438Z",
     "start_time": "2020-07-09T03:12:33.829838Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "img4 = cv2.imread(\"four.png\",0)\n",
    "number = img4.reshape(-1, img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:12:40.382781Z",
     "start_time": "2020-07-09T03:12:40.306777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹카메라로 숫자 인식하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:12:46.861302Z",
     "start_time": "2020-07-09T03:12:46.845702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera not opened\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "if cap.isOpened():\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if ret:\n",
    "            g_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            thr, bin_img = cv2.threshold(g_img, 110,225, cv2.THRESH_BINARY_INV)\n",
    "            contours, hierarchy = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, \n",
    "                                                   cv2.CHAIN_APPROX_SIMPLE)\n",
    "            try:\n",
    "                for i in range(len(contours)):\n",
    "                    contour = contours[i]\n",
    "                    (x,y), radius = cv2.minEnclosingCircle(contour)\n",
    "                    if radius > 3:\n",
    "                        xs, xe = int(x-radius), int(x+radius)\n",
    "                        ys,ye = int(y-radius), int(y+radius)\n",
    "                        cv2.rectangle(bin_img,(xs, ys),(xe,ye),\n",
    "                                     (200,0,0),1)\n",
    "                        roi = bin_img[ys:ye, xs:xe]\n",
    "                        dst = cv2.resize(roi, dsize = (50,50), interpolation=cv2.INTER_AREA)\n",
    "                        dst = cv2.resize(roi, dsize = (16,16), interpolation=cv2.INTER_AREA)\n",
    "                        A = np.zeros((20,20))\n",
    "                        A[2:-2,2:-2] = dst[:,:]\n",
    "                        A = A.reshape(-1,20,20,1)\n",
    "                        num = model.predict(A)\n",
    "                        cv2.putTextt(bin_img, str(num),(xs, ys), cv2.FONT_HERSHEY_PLAIN,2.(200,0,0))\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            cv2.imshow(\"Image\",bin_img)\n",
    "            if cv2.waitKey(1)&0xFF == 27 : # ESC\n",
    "                break\n",
    "        else:\n",
    "            print(\"no frame\")\n",
    "            break\n",
    "else:\n",
    "    print(\"camera not opened\")\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:12:53.245575Z",
     "start_time": "2020-07-09T03:12:53.229975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T05:54:49.458178Z",
     "start_time": "2020-07-09T05:54:49.453177Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2, \n",
    "                                  shear_range=0.2, zoom_range= 0.2,\n",
    "                                  horizontal_flip = True,\n",
    "                                  fill_mode=\"nearest\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2, \n",
    "                                  shear_range=0.2, zoom_range= 0.2,\n",
    "                                  horizontal_flip = True,\n",
    "                                  fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T05:55:25.179255Z",
     "start_time": "2020-07-09T05:55:18.697Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "img0 = cv2.imread(\"digits/1/1000.jpg\",0)\n",
    "x =img0.reshape(-1,20,20,1)\n",
    "\n",
    "for batch in train_datagen.flow(x, batch_size=1,\n",
    "                               save_to_dir=\"digits\",save_prefix=\"zero\",\n",
    "                               save_format=\"jpeg\"):\n",
    "    i+=1\n",
    "    if i >20 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T06:02:21.795514Z",
     "start_time": "2020-07-09T06:02:21.666506Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "with open(\"digits_model.json\",\"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "    model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T06:02:31.418051Z",
     "start_time": "2020-07-09T06:02:31.415051Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(filepath = \"digits-{epoch:03d}-{val_acc:.4f}.hdf5\",\n",
    "                            monitor=\"val_acc\", save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T06:02:41.041183Z",
     "start_time": "2020-07-09T06:02:41.038183Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_acc\", patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T06:02:50.642267Z",
     "start_time": "2020-07-09T06:02:50.596264Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model.compile(loss= tf.keras.losses.categorical_crossentropy,\n",
    "             optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "             metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T06:05:11.651241Z",
     "start_time": "2020-07-09T06:05:10.277765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/110 [===========================>..] - ETA: 0s - loss: 2.2787 - acc: 0.1470\n",
      "Epoch 00001: val_acc did not improve from 0.83400\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 2.2771 - acc: 0.1474 - val_loss: 2.1986 - val_acc: 0.1647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d153508>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_datagen.flow(train_x, train_y),\n",
    "          # steps_per_epoch= len(trian_x) / 128,\n",
    "          validation_data = test_datagen.flow(test_x, test_y),\n",
    "         callbacks=[checkpoint, early_stopping],\n",
    "         batch_size=500,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "if cap.isOpened():\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if ret:\n",
    "            g_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            thr, bin_img = cv2.threshold(g_img, 110,225, cv2.THRESH_BINARY_INV)\n",
    "            contours, hierarchy = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, \n",
    "                                                   cv2.CHAIN_APPROX_SIMPLE)\n",
    "            try:\n",
    "                for i in range(len(contours)):\n",
    "                    contour = contours[i]\n",
    "                    (x,y), radius = cv2.minEnclosingCircle(contour)\n",
    "                    if radius > 3:\n",
    "                        xs, xe = int(x-radius), int(x+radius)\n",
    "                        ys,ye = int(y-radius), int(y+radius)\n",
    "                        cv2.rectangle(bin_img,(xs, ys),(xe,ye),\n",
    "                                     (200,0,0),1)\n",
    "                        roi = bin_img[ys:ye, xs:xe]\n",
    "                        dst = cv2.resize(roi, dsize = (50,50), interpolation=cv2.INTER_AREA)\n",
    "                        dst = cv2.resize(roi, dsize = (16,16), interpolation=cv2.INTER_AREA)\n",
    "                        A = np.zeros((20,20))\n",
    "                        A[2:-2,2:-2] = dst[:,:]\n",
    "                        A = A.reshape(-1,20,20,1)\n",
    "                        num = model.predict(A)\n",
    "                        cv2.putTextt(bin_img, str(num),(xs, ys), cv2.FONT_HERSHEY_PLAIN,2.(200,0,0))\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            cv2.imshow(\"Image\",bin_img)\n",
    "            if cv2.waitKey(1)&0xFF == 27 : # ESC\n",
    "                break\n",
    "        else:\n",
    "            print(\"no frame\")\n",
    "            break\n",
    "else:\n",
    "    print(\"camera not opened\")\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
